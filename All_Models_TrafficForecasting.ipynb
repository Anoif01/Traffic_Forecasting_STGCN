{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 7692357,
          "sourceType": "datasetVersion",
          "datasetId": 4013295
        },
        {
          "sourceId": 7940524,
          "sourceType": "datasetVersion",
          "datasetId": 4668457
        }
      ],
      "dockerImageVersionId": 30673,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "collapsed_sections": [
        "F_UBEtBY0xQV",
        "xerCK5-I05CX",
        "209rgI991CSX",
        "wTKAjjMz2GKO",
        "oa-QZcDm2TxN",
        "14V2pkr02h6C",
        "NEPqlZOon9dl"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "732215489d884c14b720daef281d04be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d68e45427f0547ed9b18794dcf26f694",
              "IPY_MODEL_8a6f63ccd6854f7c9a1b06112ae8f675",
              "IPY_MODEL_fb23587e81e4475392629494fce22cdd"
            ],
            "layout": "IPY_MODEL_52558dcc6aa948b8b2f9a12b31618e71"
          }
        },
        "d68e45427f0547ed9b18794dcf26f694": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c7d625e5b394d878c97090f06805437",
            "placeholder": "​",
            "style": "IPY_MODEL_07f89884c05a4f1ca8dca42cda5ba8c2",
            "value": "  8%"
          }
        },
        "8a6f63ccd6854f7c9a1b06112ae8f675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_140d93622aa24505aa4c608293bd03be",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_097ca53a64e64a8da87e017ffb3a0c98",
            "value": 40
          }
        },
        "fb23587e81e4475392629494fce22cdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fe4b0c4d7784bc4b6d79d863a45e997",
            "placeholder": "​",
            "style": "IPY_MODEL_5500d29dca1149deb137d3d6c8d51946",
            "value": " 40/500 [03:21&lt;37:22,  4.87s/it]"
          }
        },
        "52558dcc6aa948b8b2f9a12b31618e71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7d625e5b394d878c97090f06805437": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07f89884c05a4f1ca8dca42cda5ba8c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "140d93622aa24505aa4c608293bd03be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "097ca53a64e64a8da87e017ffb3a0c98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3fe4b0c4d7784bc4b6d79d863a45e997": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5500d29dca1149deb137d3d6c8d51946": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8f3e03dde5274f30ad3f6f203d460d7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_03c3edbc675248ceadd7c01bb7cecdf0",
              "IPY_MODEL_259a55c02de7476ba49f8e979039595e"
            ],
            "layout": "IPY_MODEL_224a594fab5843b795f8c937127bb69f"
          }
        },
        "03c3edbc675248ceadd7c01bb7cecdf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e2001cfb1c4542be5d64aaaa5dda97",
            "placeholder": "​",
            "style": "IPY_MODEL_626fb3cab4f545c0948419d859df2e82",
            "value": "0.019 MB of 0.019 MB uploaded\r"
          }
        },
        "259a55c02de7476ba49f8e979039595e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e54d0dffb96496b82ef028b01e5d3fb",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_27299541c72345898198c70cd7b89c8f",
            "value": 1
          }
        },
        "224a594fab5843b795f8c937127bb69f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e2001cfb1c4542be5d64aaaa5dda97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626fb3cab4f545c0948419d859df2e82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2e54d0dffb96496b82ef028b01e5d3fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27299541c72345898198c70cd7b89c8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f63d17cdbb3d49788096f4c518c73273": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3c941798bdfb45fc9cfc02ffdea26fdd",
              "IPY_MODEL_94643ea2c6a54c7481ebc3b671c942b1",
              "IPY_MODEL_c0e755d78b5c4cde8afa8188d10d2a1f"
            ],
            "layout": "IPY_MODEL_3721215d16b54fa2a6c723efd0df4d7b"
          }
        },
        "3c941798bdfb45fc9cfc02ffdea26fdd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ea50619213d94639b7228e1be175211a",
            "placeholder": "​",
            "style": "IPY_MODEL_60a2849df78540d9bb00f51b517feae9",
            "value": " 10%"
          }
        },
        "94643ea2c6a54c7481ebc3b671c942b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed567d815a4b495ab008f427225cb454",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3d666c663d164f0181289bcb81061db6",
            "value": 49
          }
        },
        "c0e755d78b5c4cde8afa8188d10d2a1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_89b60de633f0460bbf1efe7103a47b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_2e7dd189ad78418da36de544e9b94522",
            "value": " 49/500 [05:09&lt;46:32,  6.19s/it]"
          }
        },
        "3721215d16b54fa2a6c723efd0df4d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea50619213d94639b7228e1be175211a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60a2849df78540d9bb00f51b517feae9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed567d815a4b495ab008f427225cb454": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3d666c663d164f0181289bcb81061db6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "89b60de633f0460bbf1efe7103a47b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e7dd189ad78418da36de544e9b94522": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b138cec91e604eec82dce0d043364910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f0ede87b1e3a45b4885b36d2f8dac736",
              "IPY_MODEL_d64b3801d5164448bb3a066a98383bc7"
            ],
            "layout": "IPY_MODEL_2143f35d3f5141eeb54860cf20797ae0"
          }
        },
        "f0ede87b1e3a45b4885b36d2f8dac736": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_240cda871a434c82b0da184732b98a81",
            "placeholder": "​",
            "style": "IPY_MODEL_f358b7a76fc44a77accebd61f08dca93",
            "value": "0.020 MB of 0.020 MB uploaded\r"
          }
        },
        "d64b3801d5164448bb3a066a98383bc7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db99800246bf4c7297dc590337773f70",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5f84cb5831074a00929171dd0e5b7353",
            "value": 1
          }
        },
        "2143f35d3f5141eeb54860cf20797ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "240cda871a434c82b0da184732b98a81": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f358b7a76fc44a77accebd61f08dca93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "db99800246bf4c7297dc590337773f70": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f84cb5831074a00929171dd0e5b7353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d23888c1ee541c19ce7f59a31f55a19": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9481ed10530f4995a37399b4d15e421c",
              "IPY_MODEL_73c82d86ddd243feb6854ab5eba1f333",
              "IPY_MODEL_bfc017f005c04fe0814c60af8a997e7a"
            ],
            "layout": "IPY_MODEL_20d5d8810a644203bec8d6b0a0079865"
          }
        },
        "9481ed10530f4995a37399b4d15e421c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_563b123138194b68b865d23e9135309f",
            "placeholder": "​",
            "style": "IPY_MODEL_0926c57994484f3eb7503e3fd56c61ec",
            "value": "  7%"
          }
        },
        "73c82d86ddd243feb6854ab5eba1f333": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5810f3cc38bf43f4a06221c1e799a73e",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_18571e4e7c1d40aba470170447f5a523",
            "value": 33
          }
        },
        "bfc017f005c04fe0814c60af8a997e7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fb0d6932f1c14864a745f9bda8582fed",
            "placeholder": "​",
            "style": "IPY_MODEL_4f9533baa79e4122bc5a873e4b7c163a",
            "value": " 33/500 [37:25&lt;8:34:47, 66.14s/it]"
          }
        },
        "20d5d8810a644203bec8d6b0a0079865": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "563b123138194b68b865d23e9135309f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0926c57994484f3eb7503e3fd56c61ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5810f3cc38bf43f4a06221c1e799a73e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "18571e4e7c1d40aba470170447f5a523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fb0d6932f1c14864a745f9bda8582fed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f9533baa79e4122bc5a873e4b7c163a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59367b8003794475b9f4c2220414f7b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d93001e532854ef39cf8d8c4850919d7",
              "IPY_MODEL_a1cb4f02955c4d12bc5e878d222c8957"
            ],
            "layout": "IPY_MODEL_238f72da0c734f4b93b43692bddb16ee"
          }
        },
        "d93001e532854ef39cf8d8c4850919d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b677953ea4041f382ac6a232e046316",
            "placeholder": "​",
            "style": "IPY_MODEL_f4ebee75a8214fafb112e673d2f3c3c3",
            "value": "0.018 MB of 0.018 MB uploaded\r"
          }
        },
        "a1cb4f02955c4d12bc5e878d222c8957": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0d7ee95ff4a84fb8be026f01dd67d95d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1af6ee831b7a4f1493d1e9efa2aab0f6",
            "value": 1
          }
        },
        "238f72da0c734f4b93b43692bddb16ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b677953ea4041f382ac6a232e046316": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4ebee75a8214fafb112e673d2f3c3c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d7ee95ff4a84fb8be026f01dd67d95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1af6ee831b7a4f1493d1e9efa2aab0f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d5799b61264a489f80d620c088de6bae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_54437f31fd734df0b7cf47e1e22fa956",
              "IPY_MODEL_726b8352e5634dfa8109be6b9e1311ab",
              "IPY_MODEL_9ae356a219534c568359039479a3b6c9"
            ],
            "layout": "IPY_MODEL_bd65aa02570d40d0be635657e09425de"
          }
        },
        "54437f31fd734df0b7cf47e1e22fa956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c972d7580e134b9cae8986ac041f4d74",
            "placeholder": "​",
            "style": "IPY_MODEL_c261175753974ce39109119d72c65c31",
            "value": "  6%"
          }
        },
        "726b8352e5634dfa8109be6b9e1311ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a12d42248e4c4cf98ed9315b5f35c5c0",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d47ea30916744539bca05985593efc53",
            "value": 32
          }
        },
        "9ae356a219534c568359039479a3b6c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f39faaed4b54a7d9ed7db8264918155",
            "placeholder": "​",
            "style": "IPY_MODEL_1121bac1e7f94b29a6e51ad409bb99e9",
            "value": " 32/500 [46:23&lt;10:59:08, 84.51s/it]"
          }
        },
        "bd65aa02570d40d0be635657e09425de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c972d7580e134b9cae8986ac041f4d74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c261175753974ce39109119d72c65c31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a12d42248e4c4cf98ed9315b5f35c5c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d47ea30916744539bca05985593efc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f39faaed4b54a7d9ed7db8264918155": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1121bac1e7f94b29a6e51ad409bb99e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d3222e6c170c46ac92f9e52f0ac63fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7026fd4fe5cd4b45be69d1727c8513d9",
              "IPY_MODEL_634c4ff78fc648ee98cbbeeb63a0edf2"
            ],
            "layout": "IPY_MODEL_8c1cd294ef904dd18077fe13c5af4d53"
          }
        },
        "7026fd4fe5cd4b45be69d1727c8513d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a97c617e66948378c3e54712dfece44",
            "placeholder": "​",
            "style": "IPY_MODEL_2a94600cd1d4451d9fb6653f0a9d4a04",
            "value": "0.018 MB of 0.018 MB uploaded\r"
          }
        },
        "634c4ff78fc648ee98cbbeeb63a0edf2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_903417ab9e1e425dbc5e135c87e1225d",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9d8fedbe7de4579847530cc151348ca",
            "value": 1
          }
        },
        "8c1cd294ef904dd18077fe13c5af4d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a97c617e66948378c3e54712dfece44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a94600cd1d4451d9fb6653f0a9d4a04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "903417ab9e1e425dbc5e135c87e1225d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9d8fedbe7de4579847530cc151348ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anoif01/Traffic_Forecasting_STGCN/blob/main/All_Models_TrafficForecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q wandb\n",
        "!pip install mamba-ssm --no-build-isolation -q\n",
        "from mamba_ssm import Mamba"
      ],
      "metadata": {
        "id": "x5SC-TAbYraT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637ba5f2-882b-43ad-cae7-99fa5d7532ae"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/85.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m25.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for mamba-ssm (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
            "/usr/local/lib/python3.10/dist-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, dout, *args):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as init\n",
        "import torch.nn.functional as F\n",
        "\n",
        "# from torchsummary import summary\n",
        "# from Param import *\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import random\n",
        "import sys\n",
        "import math\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.sparse.linalg import eigs\n",
        "import scipy.sparse as ss\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from datetime import datetime\n",
        "import time\n",
        "\n",
        "# pandas progress bar and learning progress bar\n",
        "from tqdm.notebook import tqdm\n",
        "tqdm.pandas()\n",
        "from IPython.display import display\n",
        "\n",
        "import wandb\n",
        "from argparse import Namespace\n",
        "import gc\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Personal_Project/Traffic_Prediction/')\n",
        "os.environ['CUBLAS_WORKSPACE_CONFIG'] = \":4096:8\"\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "# Read credentiels\n",
        "from google.colab import userdata\n",
        "WANDB_TOKEN = userdata.get('WANDB_KEY')"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:28.203307Z",
          "iopub.execute_input": "2024-04-03T14:07:28.204028Z",
          "iopub.status.idle": "2024-04-03T14:07:35.220097Z",
          "shell.execute_reply.started": "2024-04-03T14:07:28.203992Z",
          "shell.execute_reply": "2024-04-03T14:07:35.218959Z"
        },
        "trusted": true,
        "id": "KAYwZMvSStZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6912c9dd-fae9-49fd-8368-4c1a7a5db082"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Functions/Classes Def\n"
      ],
      "metadata": {
        "id": "RSon7WRE0rOm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Dataset Func\n"
      ],
      "metadata": {
        "id": "F_UBEtBY0xQV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to set random seed for reproducibility\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Sets the random seed for Python's built-in random module, NumPy, and PyTorch\n",
        "    to ensure reproducibility across experiments.\n",
        "\n",
        "    Parameters:\n",
        "    seed (int): The seed value to be used for generating random numbers.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the seed for Python's hash-based operations\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "    # Set the seed for the Python random module\n",
        "    random.seed(seed)\n",
        "\n",
        "    # Set the seed for NumPy's random number generator\n",
        "    np.random.seed(seed)\n",
        "\n",
        "    # Set the seed for PyTorch's random number generator\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "    # Ensure PyTorch uses deterministic algorithms (may affect performance)\n",
        "    torch.use_deterministic_algorithms(True)"
      ],
      "metadata": {
        "id": "LXY-QsVkigDv"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getXSYS_single(data, mode):\n",
        "    \"\"\"\n",
        "    Splits the dataset into input (XS) and output (YS) sequences for training or testing.\n",
        "\n",
        "    Parameters:\n",
        "    data (np.array): The complete dataset as a NumPy array.\n",
        "    mode (str): Specifies whether to generate 'TRAIN' or 'TEST' sequences.\n",
        "\n",
        "    Returns:\n",
        "    XS (np.array): Input sequences of shape (num_samples, 1, TIMESTEP_IN, num_features).\n",
        "    YS (np.array): Output sequences of shape (num_samples, 1, 1, num_features).\n",
        "    \"\"\"\n",
        "\n",
        "    # Number of data points allocated for training\n",
        "    TRAIN_NUM = int(data.shape[0] * TRAINRATIO)\n",
        "    XS, YS = [], []\n",
        "\n",
        "    if mode == 'TRAIN':\n",
        "        # Generate training sequences\n",
        "        # Iterate over the data to create input-output pairs\n",
        "        for i in range(TRAIN_NUM - TIMESTEP_OUT - TIMESTEP_IN + 1):\n",
        "            # Input sequence (historical data)\n",
        "            x = data[i:i+TIMESTEP_IN, :]\n",
        "            # Output sequence (data to be predicted)\n",
        "            y = data[i+TIMESTEP_IN+TIMESTEP_OUT-1:i+TIMESTEP_IN+TIMESTEP_OUT, :]\n",
        "            XS.append(x)\n",
        "            YS.append(y)\n",
        "\n",
        "    elif mode == 'TEST':\n",
        "        # Generate testing sequences\n",
        "        # Iterate over the data, starting after the training portion, to create input-output pairs\n",
        "        for i in range(TRAIN_NUM - TIMESTEP_IN,  data.shape[0] - TIMESTEP_OUT - TIMESTEP_IN + 1):\n",
        "            # Input sequence (historical data)\n",
        "            x = data[i:i+TIMESTEP_IN, :]\n",
        "            # Output sequence (data to be predicted)\n",
        "            y = data[i+TIMESTEP_IN+TIMESTEP_OUT-1:i+TIMESTEP_IN+TIMESTEP_OUT, :]\n",
        "            XS.append(x)\n",
        "            YS.append(y)\n",
        "\n",
        "    # Convert lists to NumPy arrays\n",
        "    XS, YS = np.array(XS), np.array(YS)\n",
        "    # Add an extra dimension for the convolutional channel\n",
        "    XS, YS = XS[:, np.newaxis, :, :], YS[:, np.newaxis, :]\n",
        "\n",
        "    return XS, YS"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:35.269982Z",
          "iopub.execute_input": "2024-04-03T14:07:35.270348Z",
          "iopub.status.idle": "2024-04-03T14:07:35.284218Z",
          "shell.execute_reply.started": "2024-04-03T14:07:35.270311Z",
          "shell.execute_reply": "2024-04-03T14:07:35.283257Z"
        },
        "trusted": true,
        "id": "em0hOYF7StZK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(XS, YS, device, mode):\n",
        "    if mode == \"TRAIN_VALID\":\n",
        "        # add XS array and YS array on GPU device\n",
        "        XS_torch, YS_torch = torch.Tensor(XS).to(device), torch.Tensor(YS).to(device)\n",
        "\n",
        "        # create train_valid Dataset\n",
        "        trainval_data = torch.utils.data.TensorDataset(XS_torch, YS_torch)\n",
        "        trainval_size = len(trainval_data)\n",
        "\n",
        "        # calculate the real train size\n",
        "        train_size = int(trainval_size * (1-TRAINVALSPLIT))\n",
        "\n",
        "        # gather train data and valid data\n",
        "        train_data = torch.utils.data.Subset(trainval_data, list(range(0, train_size)))\n",
        "        val_data = torch.utils.data.Subset(trainval_data, list(range(train_size, trainval_size)))\n",
        "\n",
        "        print(f\"Original Train_Valid Dataset size: {trainval_size}.\")\n",
        "        print(f\"Train Dataset size: {len(train_data)}.\")\n",
        "        print(f\"Valide Dataset size: {len(val_data)}.\")\n",
        "\n",
        "        # create the dataloaders\n",
        "        train_iter = torch.utils.data.DataLoader(train_data, BATCHSIZE, shuffle=True)\n",
        "        val_iter = torch.utils.data.DataLoader(val_data, BATCHSIZE, shuffle=True)\n",
        "        return train_iter, val_iter\n",
        "\n",
        "    elif mode == \"TEST\":\n",
        "        # add XS array and YS array on GPU device\n",
        "        XS_torch, YS_torch = torch.Tensor(XS).to(device), torch.Tensor(YS).to(device)\n",
        "\n",
        "        # create train_valid Dataset\n",
        "        test_data = torch.utils.data.TensorDataset(XS_torch, YS_torch)\n",
        "        test_size = len(test_data)\n",
        "        print(f\"Test Dataset size: {test_size}.\")\n",
        "\n",
        "        # create the dataloaders\n",
        "        test_iter = torch.utils.data.DataLoader(test_data, BATCHSIZE, shuffle=False)\n",
        "        return test_iter"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:35.285514Z",
          "iopub.execute_input": "2024-04-03T14:07:35.285932Z",
          "iopub.status.idle": "2024-04-03T14:07:35.298641Z",
          "shell.execute_reply.started": "2024-04-03T14:07:35.285901Z",
          "shell.execute_reply": "2024-04-03T14:07:35.297722Z"
        },
        "trusted": true,
        "id": "lsIwTi7HStZK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2 Evaluate"
      ],
      "metadata": {
        "id": "xerCK5-I05CX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_func(y_true, y_pred, precision=10):\n",
        "    # print('MSE:', round(MSE(y_true, y_pred), precision))\n",
        "    # print('RMSE:', round(RMSE(y_true, y_pred), precision))\n",
        "    # print('MAE:', round(MAE(y_true, y_pred), precision))\n",
        "    # print('MAPE:', round(MAPE(y_true, y_pred), precision), '%')\n",
        "    # print('PCC:', round(PCC(y_true, y_pred), precision))\n",
        "    return MSE_func(y_true, y_pred), RMSE_func(y_true, y_pred), MAE_func(y_true, y_pred), MAPE_func(y_true, y_pred)\n",
        "\n",
        "def MSE_func(y_true, y_pred):\n",
        "    y_true[y_true < 1e-5] = 0\n",
        "    y_pred[y_pred < 1e-5] = 0\n",
        "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
        "        mask = np.not_equal(y_true, 0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask /= np.mean(mask)\n",
        "        mse = np.square(y_pred - y_true)\n",
        "        mse = np.nan_to_num(mse * mask)\n",
        "        mse = np.mean(mse)\n",
        "        return mse\n",
        "\n",
        "def RMSE_func(y_true, y_pred):\n",
        "    y_true[y_true < 1e-5] = 0\n",
        "    y_pred[y_pred < 1e-5] = 0\n",
        "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
        "        mask = np.not_equal(y_true, 0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask /= np.mean(mask)\n",
        "        rmse = np.square(np.abs(y_pred - y_true))\n",
        "        rmse = np.nan_to_num(rmse * mask)\n",
        "        rmse = np.sqrt(np.mean(rmse))\n",
        "        return rmse\n",
        "\n",
        "def MAE_func(y_true, y_pred):\n",
        "    y_true[y_true < 1e-5] = 0\n",
        "    y_pred[y_pred < 1e-5] = 0\n",
        "    with np.errstate(divide = 'ignore', invalid = 'ignore'):\n",
        "        mask = np.not_equal(y_true, 0)\n",
        "        mask = mask.astype(np.float32)\n",
        "        mask /= np.mean(mask)\n",
        "        mae = np.abs(y_pred - y_true)\n",
        "        mae = np.nan_to_num(mae * mask)\n",
        "        mae = np.mean(mae)\n",
        "        return mae\n",
        "\n",
        "def MAPE_func(y_true, y_pred, null_val=0):\n",
        "    y_true[y_true < 1e-5] = 0\n",
        "    y_pred[y_pred < 1e-5] = 0\n",
        "    with np.errstate(divide='ignore', invalid='ignore'):\n",
        "        if np.isnan(null_val):\n",
        "            mask = ~np.isnan(y_true)\n",
        "        else:\n",
        "            mask = np.not_equal(y_true, null_val)\n",
        "        mask = mask.astype('float32')\n",
        "        mask /= np.mean(mask)\n",
        "        mape = np.abs(np.divide((y_pred - y_true).astype('float32'), y_true))\n",
        "        mape = np.nan_to_num(mask * mape)\n",
        "        return np.mean(mape) * 100"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:35.23027Z",
          "iopub.execute_input": "2024-04-03T14:07:35.230634Z",
          "iopub.status.idle": "2024-04-03T14:07:35.251465Z",
          "shell.execute_reply.started": "2024-04-03T14:07:35.230588Z",
          "shell.execute_reply": "2024-04-03T14:07:35.250255Z"
        },
        "trusted": true,
        "id": "M6ha9YX1StZI"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluateModel(model, criterion, data_iter):\n",
        "    model.eval()\n",
        "    l_sum, n = 0.0, 0\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_iter:\n",
        "            y_pred = model(x)\n",
        "            l = criterion(y_pred, y)\n",
        "            l_sum += l.item() * y.shape[0]\n",
        "            n += y.shape[0]\n",
        "        return l_sum / n\n",
        "\n",
        "def predictModel(model, data_iter):\n",
        "    YS_pred = []\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for x, y in data_iter:\n",
        "            YS_pred_batch = model(x)\n",
        "            YS_pred_batch = YS_pred_batch.cpu().numpy()\n",
        "            YS_pred.append(YS_pred_batch)\n",
        "        YS_pred = np.vstack(YS_pred)\n",
        "    return YS_pred"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:41.610208Z",
          "iopub.execute_input": "2024-04-03T14:07:41.610663Z",
          "iopub.status.idle": "2024-04-03T14:07:41.617041Z",
          "shell.execute_reply.started": "2024-04-03T14:07:41.610637Z",
          "shell.execute_reply": "2024-04-03T14:07:41.615979Z"
        },
        "trusted": true,
        "id": "CX0XNeneStZM"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Adjacent Mat"
      ],
      "metadata": {
        "id": "209rgI991CSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def weight_matrix(W, sigma2=0.1, epsilon=0.5):\n",
        "    \"\"\"\n",
        "    Computes a weighted adjacency matrix with controlled sparsity.\n",
        "\n",
        "    Parameters:\n",
        "    W (np.ndarray): The original adjacency matrix of shape [n_route, n_route].\n",
        "    sigma2 (float): The variance scalar applied to the matrix W (default is 0.1).\n",
        "    epsilon (float): Threshold to control the sparsity of the matrix W (default is 0.5).\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The transformed weight matrix of shape [n_route, n_route],\n",
        "                with sparsity controlled by epsilon and zeros on the diagonal.\n",
        "    \"\"\"\n",
        "\n",
        "    n = W.shape[0]  # Number of nodes/routes\n",
        "\n",
        "    # Normalize the adjacency matrix by scaling down its values\n",
        "    W = W / 10000\n",
        "\n",
        "    # Replace zeros (representing no connection) with infinity\n",
        "    W[W == 0] = np.inf\n",
        "\n",
        "    # Square the matrix values\n",
        "    W2 = W * W\n",
        "\n",
        "    # Create a mask to remove self-loops (diagonal elements)\n",
        "    W_mask = (np.ones([n, n]) - np.identity(n))\n",
        "\n",
        "    # Apply the Gaussian kernel and sparsity threshold, then apply the mask\n",
        "    return np.exp(-W2 / sigma2) * (np.exp(-W2 / sigma2) >= epsilon) * W_mask\n",
        "\n",
        "def scaled_laplacian(A):\n",
        "    \"\"\"\n",
        "    Computes the scaled Laplacian matrix of an adjacency matrix A.\n",
        "\n",
        "    Parameters:\n",
        "    A (np.ndarray): The adjacency matrix of shape [n, n].\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: The scaled Laplacian matrix of shape [n, n].\n",
        "    \"\"\"\n",
        "\n",
        "    n = A.shape[0]  # Number of nodes\n",
        "\n",
        "    # Degree matrix: diagonal matrix where each diagonal element is the sum of the corresponding row in A\n",
        "    d = np.sum(A, axis=1)\n",
        "\n",
        "    # Unnormalized Laplacian matrix: L = D - A\n",
        "    L = np.diag(d) - A\n",
        "\n",
        "    # Normalize the Laplacian matrix\n",
        "    for i in range(n):\n",
        "        for j in range(n):\n",
        "            if d[i] > 0 and d[j] > 0:\n",
        "                # Normalize by the degree of nodes i and j\n",
        "                L[i, j] /= np.sqrt(d[i] * d[j])\n",
        "\n",
        "    # Compute the largest eigenvalue of the Laplacian matrix\n",
        "    lam = np.linalg.eigvals(L).max().real\n",
        "\n",
        "    # Scale the Laplacian matrix by the largest eigenvalue and subtract the identity matrix\n",
        "    return 2 * L / lam - np.eye(n)\n",
        "\n",
        "def cheb_poly(L, Ks):\n",
        "    \"\"\"\n",
        "    Computes the Chebyshev polynomials up to the Ks-th order for a given Laplacian matrix L.\n",
        "\n",
        "    Parameters:\n",
        "    L (np.ndarray): The scaled Laplacian matrix of shape [n, n].\n",
        "    Ks (int): The order up to which Chebyshev polynomials are computed.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: A tensor of Chebyshev polynomials with shape [Ks, n, n].\n",
        "    \"\"\"\n",
        "\n",
        "    n = L.shape[0]  # Number of nodes\n",
        "\n",
        "    # Initialize the list of Chebyshev polynomials\n",
        "    LL = [np.eye(n), L[:]]  # T_0(L) = I, T_1(L) = L\n",
        "\n",
        "    # Compute higher-order Chebyshev polynomials iteratively\n",
        "    for i in range(2, Ks):\n",
        "        # T_k(L) = 2 * L * T_{k-1}(L) - T_{k-2}(L)\n",
        "        LL.append(np.matmul(2 * L, LL[-1]) - LL[-2])\n",
        "\n",
        "    # Convert the list of polynomials to a NumPy array\n",
        "    return np.asarray(LL)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:39.019109Z",
          "iopub.execute_input": "2024-04-03T14:07:39.019741Z",
          "iopub.status.idle": "2024-04-03T14:07:39.048449Z",
          "shell.execute_reply.started": "2024-04-03T14:07:39.019686Z",
          "shell.execute_reply": "2024-04-03T14:07:39.047175Z"
        },
        "trusted": true,
        "id": "rPq0ApCUStZL"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Model Design"
      ],
      "metadata": {
        "id": "Nfo8sGHO1h2m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 temporal_conv_layer"
      ],
      "metadata": {
        "id": "KgoUOPxn1sWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class align(nn.Module):\n",
        "    \"\"\"\n",
        "    The align module is designed to reshape the input tensor's channel dimensions.\n",
        "    Depending on whether the input channels are greater or less than the output channels,\n",
        "    this module either reduces or increases the number of channels.\n",
        "\n",
        "    Parameters:\n",
        "    c_in (int): Number of input channels.\n",
        "    c_out (int): Number of output channels.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out):\n",
        "        super(align, self).__init__()\n",
        "        self.c_in = c_in\n",
        "        self.c_out = c_out\n",
        "\n",
        "        # If the number of input channels (c_in) is greater than the output channels (c_out),\n",
        "        # reduce the channel size using a 1x1 convolution. This acts as a linear transformation\n",
        "        # across the channel dimension.\n",
        "        if c_in > c_out:\n",
        "            self.conv1x1 = nn.Conv2d(c_in, c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # If the input channels are greater than the output channels, apply the 1x1 convolution\n",
        "        # to reduce the number of channels.\n",
        "        if self.c_in > self.c_out:\n",
        "            return self.conv1x1(x)\n",
        "\n",
        "        # If the input channels are less than the output channels, pad the input tensor\n",
        "        # to increase the number of channels. The padding is added to the second dimension\n",
        "        # (channels) while keeping other dimensions unchanged.\n",
        "        if self.c_in < self.c_out:\n",
        "            # Pad format: [pad_left, pad_right, pad_top, pad_bottom, pad_front, pad_back, ...]\n",
        "            return F.pad(x, [0, 0, 0, 0, 0, self.c_out - self.c_in, 0, 0])\n",
        "\n",
        "        # If the input and output channels are the same, return the input tensor unchanged.\n",
        "        return x"
      ],
      "metadata": {
        "id": "qAcfnVGS2REl"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class temporal_conv_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Temporal Convolution Layer designed to extract spatio-temporal features.\n",
        "    This layer can use either Gated Linear Units (GLU) or traditional activation functions\n",
        "    like sigmoid or ReLU.\n",
        "\n",
        "    Parameters:\n",
        "    kt (int): The size of the temporal convolution kernel.\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kt, c_in, c_out, act=\"relu\"):\n",
        "        super(temporal_conv_layer, self).__init__()\n",
        "        self.kt = kt  # Temporal kernel size\n",
        "        self.act = act  # Activation function\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "\n",
        "        # Align input channels to output channels if necessary\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Define the convolution layer\n",
        "        # The kernel size is (kt, 1), which implies a 1D convolution over the temporal dimension\n",
        "        if self.act == \"GLU\":\n",
        "            # GLU requires double the number of output channels\n",
        "            self.conv = nn.Conv2d(c_in, c_out * 2, (kt, 1), 1)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(c_in, c_out, (kt, 1), 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        # Only take the last `kt-1` time steps from the aligned input\n",
        "        x_in = self.align(x)[:, :, self.kt-1:, :]\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # Apply the convolution, then use GLU activation\n",
        "            x_conv = self.conv(x)\n",
        "            # GLU: (x_conv * sigmoid(x_conv)) after adding residual connection (x_in)\n",
        "            return (x_conv[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_conv[:, self.c_out:, :, :])\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # Apply the convolution and sigmoid activation\n",
        "            return torch.sigmoid(self.conv(x) + x_in)\n",
        "\n",
        "        # Default ReLU activation for positive linear unit activation\n",
        "        return torch.relu(self.conv(x) + x_in)"
      ],
      "metadata": {
        "id": "nS3iHSgp1zgI"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dilated_temporal_conv_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Dilated Temporal Convolution Layer designed to extract spatio-temporal features\n",
        "    using dilated convolutions. This layer can use either Gated Linear Units (GLU) or\n",
        "    traditional activation functions like sigmoid or ReLU.\n",
        "\n",
        "    Parameters:\n",
        "    kt (int): The size of the temporal convolution kernel.\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kt, c_in, c_out, act=\"relu\"):\n",
        "        super(dilated_temporal_conv_layer, self).__init__()\n",
        "        self.kt = kt  # Temporal kernel size\n",
        "        self.act = act  # Activation function\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "\n",
        "        # Align input channels to output channels if necessary\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Define the dilated convolution layer\n",
        "        # The kernel size is (kt, 1), implying a 1D convolution over the temporal dimension\n",
        "        # Padding and dilation are used to expand the receptive field\n",
        "        if self.act == \"GLU\":\n",
        "            # For GLU, double the number of output channels\n",
        "            # Padding is set to (2, 0) to ensure the output size matches the input size\n",
        "            # Dilation expands the kernel's receptive field\n",
        "            self.conv = nn.Conv2d(c_in, c_out * 2, (kt, 1), 1, padding=(2, 0), dilation=2)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(c_in, c_out, (kt, 1), 1, padding=(2, 0), dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Align channels\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # Apply the convolution, then use GLU activation\n",
        "            x_conv = self.conv(x)\n",
        "            # GLU: (x_conv * sigmoid(x_conv)) after adding residual connection (x_in)\n",
        "            return (x_conv[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_conv[:, self.c_out:, :, :])\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # Apply the convolution and sigmoid activation\n",
        "            return torch.sigmoid(self.conv(x) + x_in)\n",
        "\n",
        "        # Default ReLU activation for positive linear unit activation\n",
        "        return torch.relu(self.conv(x) + x_in)"
      ],
      "metadata": {
        "id": "__eWQWwT1znC"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class dilated_no0_temporal_conv_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Dilated Temporal Convolution Layer without zero-padding, designed to extract\n",
        "    spatio-temporal features using dilated convolutions. This layer can use either\n",
        "    Gated Linear Units (GLU) or traditional activation functions like sigmoid or ReLU.\n",
        "\n",
        "    Parameters:\n",
        "    kt (int): The size of the temporal convolution kernel.\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, kt, c_in, c_out, act=\"relu\"):\n",
        "        super(dilated_no0_temporal_conv_layer, self).__init__()\n",
        "        self.kt = kt  # Temporal kernel size\n",
        "        self.act = act  # Activation function\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "\n",
        "        # Align input channels to output channels if necessary\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Define the dilated convolution layer\n",
        "        # The kernel size is (kt, 1), implying a 1D convolution over the temporal dimension\n",
        "        # Dilation expands the receptive field\n",
        "        if self.act == \"GLU\":\n",
        "            # For GLU, double the number of output channels\n",
        "            self.conv = nn.Conv2d(c_in, c_out * 2, (kt, 1), 1, dilation=2)\n",
        "        else:\n",
        "            self.conv = nn.Conv2d(c_in, c_out, (kt, 1), 1, dilation=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Align channels\n",
        "\n",
        "        # Apply padding using the 'replicate' mode to pad the third dimension.\n",
        "        # Here, padding is applied to the third dimension, ensuring no zeros are introduced.\n",
        "        pad_x = F.pad(x, [0, 0, 0, self.kt + 2 - 1], mode=\"replicate\")\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # Apply the convolution, then use GLU activation\n",
        "            x_conv = self.conv(pad_x)\n",
        "            # GLU: (x_conv * sigmoid(x_conv)) after adding residual connection (x_in)\n",
        "            return (x_conv[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_conv[:, self.c_out:, :, :])\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # Apply the convolution and sigmoid activation\n",
        "            return torch.sigmoid(self.conv(pad_x) + x_in)\n",
        "\n",
        "        # Default ReLU activation for positive linear unit activation\n",
        "        return torch.relu(self.conv(pad_x) + x_in)"
      ],
      "metadata": {
        "id": "1M2FMAZA1zqd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class temporal_lstm_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Temporal LSTM Layer designed to extract spatio-temporal features using LSTM units.\n",
        "    This layer supports Gated Linear Units (GLU), sigmoid, or ReLU as activation functions.\n",
        "\n",
        "    Parameters:\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    T_IN (int): The number of input time steps.\n",
        "    BATCHSIZE (int): The batch size.\n",
        "    N_NODE (int): The number of nodes (or spatial dimension).\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, act=\"relu\"):\n",
        "        super(temporal_lstm_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "\n",
        "        # Align input channels to output channels if necessary\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Select LSTM configuration based on the type of LSTM (standard or bidirectional) and activation function\n",
        "        if is_STG_LSTM:\n",
        "            if self.act == \"GLU\":\n",
        "                # LSTM with GLU activation, doubling the output channels\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out * 2, num_layers=1, batch_first=False)\n",
        "            else:\n",
        "                # Standard LSTM\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out, num_layers=1, batch_first=False)\n",
        "\n",
        "        elif is_STG_BiLSTM:\n",
        "            if self.act == \"GLU\":\n",
        "                # Bidirectional LSTM with GLU activation\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out, num_layers=1, bidirectional=True, batch_first=False)\n",
        "            else:\n",
        "                # Bidirectional LSTM with reduced output channels\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=int(c_out / 2), num_layers=1, bidirectional=True, batch_first=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Aligned input shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "\n",
        "        # Permute dimensions to prepare for LSTM (time step dimension first)\n",
        "        x_permut = x.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_in))  # Shape: [T_IN, batch_size*N_NODE, c_out]\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # LSTM with GLU activation\n",
        "            x_lstm, _ = self.lstm(x_reshape)\n",
        "            x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out * 2).permute(1, 3, 0, 2)\n",
        "            x_out = (x_lstm[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_lstm[:, self.c_out:, :, :])\n",
        "            return x_out\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # LSTM with sigmoid activation\n",
        "            x_lstm, _ = self.lstm(x_reshape)\n",
        "            x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "            x_out = torch.sigmoid(x_lstm) + x_in\n",
        "            return x_out\n",
        "\n",
        "        # Default ReLU activation for LSTM\n",
        "        x_lstm, _ = self.lstm(x_reshape)\n",
        "        x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        x_out = torch.relu(x_lstm) + x_in\n",
        "        return x_out"
      ],
      "metadata": {
        "id": "ftNIspXdJMJw"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention_lstm_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention LSTM Layer designed to extract spatio-temporal features using LSTM units combined with attention mechanisms.\n",
        "    This layer supports Gated Linear Units (GLU), sigmoid, or ReLU as activation functions.\n",
        "\n",
        "    Parameters:\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    T_IN (int): The number of input time steps.\n",
        "    BATCHSIZE (int): The batch size.\n",
        "    N_NODE (int): The number of nodes (or spatial dimension).\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, act=\"relu\"):\n",
        "        super(attention_lstm_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "\n",
        "        # Configure LSTM and attention layers based on the type of LSTM (standard or bidirectional) and activation function\n",
        "        if is_STG_AttentionLSTM:\n",
        "            self.align = align(c_in, c_out)  # Align input channels to output channels\n",
        "            if self.act == \"GLU\":\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out * 2, num_layers=1, batch_first=False)\n",
        "                self.attention = nn.Linear(c_out, 1)\n",
        "            else:\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out, num_layers=1, batch_first=False)\n",
        "                self.attention = nn.Linear(c_out, 1)\n",
        "        elif is_STG_BiAttentionLSTM:\n",
        "            self.align = align(c_in, c_out)  # Align input channels to output channels\n",
        "            if self.act == \"GLU\":\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=c_out, num_layers=1, bidirectional=True, batch_first=False)\n",
        "                self.attention = nn.Linear(c_out, 1)\n",
        "            else:\n",
        "                self.lstm = nn.LSTM(input_size=c_in, hidden_size=int(c_out / 2), num_layers=1, bidirectional=True, batch_first=False)\n",
        "                self.attention = nn.Linear(c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "\n",
        "        # Permute dimensions to prepare for LSTM (time step dimension first)\n",
        "        x_permut = x.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_in))  # Shape: [T_IN, batch_size*N_NODE, c_in]\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # LSTM with GLU activation\n",
        "            x_lstm, _ = self.lstm(x_reshape)  # Shape: [T_IN, batch_size*N_NODE, 2*c_out]\n",
        "            x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out * 2).permute(1, 3, 0, 2)\n",
        "            x_out = (x_lstm[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_lstm[:, self.c_out:, :, :])  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "\n",
        "            # Compute attention weights along the time dimension\n",
        "            x_out = x_out.permute(0, 2, 3, 1)  # Shape: [batch_size, T_IN, N_NODE, c_out]\n",
        "            attn_weights = torch.softmax(self.attention(x_out), dim=1)  # Shape: [batch_size, T_IN, N_NODE, 1]\n",
        "            weighted_output = x_out * attn_weights  # Shape: [batch_size, T_IN, N_NODE, c_out]\n",
        "            attn_output = torch.sum(weighted_output, dim=1)  # Shape: [batch_size, N_NODE, c_out]\n",
        "\n",
        "            x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "            return x_out, attn_output\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # LSTM with sigmoid activation\n",
        "            x_lstm, _ = self.lstm(x_reshape)\n",
        "            x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "            x_out = torch.sigmoid(x_lstm) + x_in\n",
        "            x_out = x_out.permute(0, 2, 3, 1)\n",
        "\n",
        "            # Compute attention weights and apply them\n",
        "            attn_weights = torch.softmax(self.attention(x_out), dim=1)\n",
        "            weighted_output = x_out * attn_weights\n",
        "            attn_output = torch.sum(weighted_output, dim=1)\n",
        "\n",
        "            x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "            return x_out, attn_output\n",
        "\n",
        "        # Default ReLU activation for LSTM\n",
        "        x_lstm, _ = self.lstm(x_reshape)\n",
        "        x_lstm = x_lstm.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        x_out = torch.relu(x_lstm) + x_in\n",
        "        x_out = x_out.permute(0, 2, 3, 1)\n",
        "\n",
        "        # Compute attention weights and apply them\n",
        "        attn_weights = torch.softmax(self.attention(x_out), dim=1)\n",
        "        weighted_output = x_out * attn_weights\n",
        "        attn_output = torch.sum(weighted_output, dim=1)\n",
        "\n",
        "        x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "        return x_out, attn_output"
      ],
      "metadata": {
        "id": "Eug32b0sR6YG"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class temporal_gru_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Temporal GRU Layer designed to extract spatio-temporal features using GRU (Gated Recurrent Unit) units.\n",
        "    This layer supports Gated Linear Units (GLU), sigmoid, or ReLU as activation functions.\n",
        "\n",
        "    Parameters:\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    T_IN (int): The number of input time steps.\n",
        "    BATCHSIZE (int): The batch size.\n",
        "    N_NODE (int): The number of nodes (or spatial dimension).\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, act=\"relu\"):\n",
        "        super(temporal_gru_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "        self.align = align(c_in, c_out)  # Align input channels to output channels\n",
        "\n",
        "        # Configure GRU based on the type of GRU (standard or bidirectional) and activation function\n",
        "        if is_STG_GRU:\n",
        "            if self.act == \"GLU\":\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out * 2, num_layers=1, batch_first=False)\n",
        "            else:\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out, num_layers=1, batch_first=False)\n",
        "        elif is_STG_BiGRU:\n",
        "            if self.act == \"GLU\":\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out, num_layers=1, bidirectional=True, batch_first=False)\n",
        "            else:\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=int(c_out / 2), num_layers=1, bidirectional=True, batch_first=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "\n",
        "        # Permute dimensions to prepare for GRU (time step dimension first)\n",
        "        x_permut = x.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_in))  # Shape: [T_IN, batch_size*N_NODE, c_in]\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # GRU with GLU activation\n",
        "            x_gru, _ = self.gru(x_reshape)\n",
        "            x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out * 2).permute(1, 3, 0, 2)\n",
        "            x_out = (x_gru[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_gru[:, self.c_out:, :, :])\n",
        "            return x_out\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # GRU with sigmoid activation\n",
        "            x_gru, _ = self.gru(x_reshape)\n",
        "            x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "            x_out = torch.sigmoid(x_gru) + x_in\n",
        "            return x_out\n",
        "\n",
        "        # Default ReLU activation for GRU\n",
        "        x_gru, _ = self.gru(x_reshape)\n",
        "        x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        x_out = torch.relu(x_gru) + x_in\n",
        "        return x_out\n"
      ],
      "metadata": {
        "id": "iLwVgTPEftnf"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention_gru_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Attention-based GRU Layer designed to extract spatio-temporal features with attention mechanism.\n",
        "    This layer supports Gated Linear Units (GLU), sigmoid, or ReLU as activation functions.\n",
        "\n",
        "    Parameters:\n",
        "    c_in (int): The number of input channels.\n",
        "    c_out (int): The number of output channels.\n",
        "    T_IN (int): The number of input time steps.\n",
        "    BATCHSIZE (int): The batch size.\n",
        "    N_NODE (int): The number of nodes (or spatial dimension).\n",
        "    act (str): The activation function to be used (\"GLU\", \"sigmoid\", or \"relu\").\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, act=\"relu\"):\n",
        "        super(attention_gru_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "\n",
        "        # Configure GRU based on the type of GRU (standard or bidirectional) and activation function\n",
        "        if is_STG_AttentionGRU:\n",
        "            self.align = align(c_in, c_out)\n",
        "            if self.act == \"GLU\":\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out * 2, num_layers=1, batch_first=False)\n",
        "            else:\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out, num_layers=1, batch_first=False)\n",
        "            self.attention = nn.Linear(c_out, 1)\n",
        "\n",
        "        elif is_STG_BiAttentionGRU:\n",
        "            self.align = align(c_in, c_out)\n",
        "            if self.act == \"GLU\":\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=c_out, num_layers=1, bidirectional=True, batch_first=False)\n",
        "            else:\n",
        "                self.gru = nn.GRU(input_size=c_in, hidden_size=int(c_out / 2), num_layers=1, bidirectional=True, batch_first=False)\n",
        "            self.attention = nn.Linear(c_out, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "\n",
        "        # Permute dimensions to prepare for GRU (time step dimension first)\n",
        "        x_permut = x.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_in))  # Shape: [T_IN, batch_size*N_NODE, c_in]\n",
        "\n",
        "        if self.act == \"GLU\":\n",
        "            # GRU with GLU activation\n",
        "            x_gru, _ = self.gru(x_reshape)  # Shape: [T_IN, batch_size*N_NODE, 2*c_out]\n",
        "            x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out * 2).permute(1, 3, 0, 2)\n",
        "            x_out = (x_gru[:, :self.c_out, :, :] + x_in) * torch.sigmoid(x_gru[:, self.c_out:, :, :])\n",
        "\n",
        "            # Calculate attention weights across the time steps\n",
        "            x_out = x_out.permute(0, 2, 3, 1)  # Shape: [batch_size, T_IN, N_NODE, c_out]\n",
        "            attn_weights = torch.softmax(self.attention(x_out), dim=1)  # Shape: [batch_size, T_IN, N_NODE, 1]\n",
        "\n",
        "            # Apply attention weights (weighted average)\n",
        "            weighted_output = x_out * attn_weights  # Shape: [batch_size, T_IN, N_NODE, c_out]\n",
        "\n",
        "            # Sum the weighted output to get the final attention representation\n",
        "            attn_output = torch.sum(weighted_output, dim=1)  # Shape: [batch_size, N_NODE, c_out]\n",
        "\n",
        "            # Permute back to original shape\n",
        "            x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "            return x_out, attn_output\n",
        "\n",
        "        if self.act == \"sigmoid\":\n",
        "            # GRU with sigmoid activation\n",
        "            x_gru, _ = self.gru(x_reshape)\n",
        "            x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "            x_out = torch.sigmoid(x_gru) + x_in\n",
        "            x_out = x_out.permute(0, 2, 3, 1)\n",
        "\n",
        "            # Calculate attention weights\n",
        "            attn_weights = torch.softmax(self.attention(x_out), dim=1)\n",
        "\n",
        "            # Apply attention weights (weighted average)\n",
        "            weighted_output = x_out * attn_weights\n",
        "\n",
        "            # Sum the weighted output to get the final attention representation\n",
        "            attn_output = torch.sum(weighted_output, dim=1)\n",
        "\n",
        "            # Permute back to original shape\n",
        "            x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "            return x_out, attn_output\n",
        "\n",
        "        # Default ReLU activation for GRU\n",
        "        x_gru, _ = self.gru(x_reshape)\n",
        "        x_gru = x_gru.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        x_out = torch.relu(x_gru) + x_in\n",
        "        x_out = x_out.permute(0, 2, 3, 1)\n",
        "\n",
        "        # Calculate attention weights\n",
        "        attn_weights = torch.softmax(self.attention(x_out), dim=1)\n",
        "\n",
        "        # Apply attention weights (weighted average)\n",
        "        weighted_output = x_out * attn_weights\n",
        "\n",
        "        # Sum the weighted output to get the final attention representation\n",
        "        attn_output = torch.sum(weighted_output, dim=1)\n",
        "\n",
        "        # Permute back to original shape\n",
        "        x_out = x_out.permute(0, 3, 1, 2)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "        return x_out, attn_output\n"
      ],
      "metadata": {
        "id": "JTx7uh0tI-gH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class transformer_layer(nn.Module):\n",
        "\n",
        "    '''\n",
        "    Transformer layer definition designed for extracting spatio-temporal features.\n",
        "    It utilizes an alignment layer followed by a Transformer Encoder to process the input data.\n",
        "\n",
        "    Parameters:\n",
        "    c_in: Number of input channels.\n",
        "    c_out: Number of output channels.\n",
        "    T_IN: Number of input time steps.\n",
        "    BATCHSIZE: Batch size.\n",
        "    N_NODE: Number of nodes (spatial dimension).\n",
        "    HEAD: Number of attention heads in the Transformer.\n",
        "    act: Activation function (default is \"relu\").\n",
        "    '''\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, HEAD, act=\"relu\"):\n",
        "        super(transformer_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "        self.HEAD = HEAD  # Number of attention heads in the Transformer\n",
        "\n",
        "        # Align layer to match input and output channels\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Transformer Encoder Layer: Processes input data with self-attention mechanism\n",
        "        self.transformer = nn.TransformerEncoderLayer(d_model=c_out, nhead=HEAD, dim_feedforward=c_out, batch_first=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "        # print(f\"Align X-in Shape: {x_in.shape}\")\n",
        "\n",
        "        # Permute dimensions to prepare for the Transformer Encoder (time step dimension first)\n",
        "        x_permut = x_in.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "\n",
        "        # Reshape to [T_IN, batch_size * N_NODE, c_out] for Transformer processing\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_out))\n",
        "        # print(f\"X-in ReShape: {x_reshape.shape}\")\n",
        "\n",
        "        # Pass the reshaped input through the Transformer Encoder\n",
        "        x_transformer = self.transformer(x_reshape)\n",
        "        # print(f\"X transformer Shape: {x_transformer.shape}\")\n",
        "\n",
        "        # Reshape the Transformer output back to the original dimensions\n",
        "        x_transformer = x_transformer.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        # print(f\"Reshape X transformer Shape: {x_transformer.shape}\")\n",
        "\n",
        "        return x_transformer  # Shape: [batch_size, c_out, T_IN, N_NODE]\n"
      ],
      "metadata": {
        "id": "QFf8yp0NrFd2"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mamba_layer(nn.Module):\n",
        "\n",
        "    '''\n",
        "    Mamba layer definition designed for extracting spatio-temporal features.\n",
        "    This layer combines channel alignment with the Mamba architecture, which includes state-space models (SSMs) and local convolutions.\n",
        "\n",
        "    Parameters:\n",
        "    c_in: Number of input channels.\n",
        "    c_out: Number of output channels.\n",
        "    T_IN: Number of input time steps.\n",
        "    BATCHSIZE: Batch size.\n",
        "    N_NODE: Number of nodes (spatial dimension).\n",
        "    d_state: SSM state expansion factor.\n",
        "    d_conv: Local convolution width.\n",
        "    act: Activation function (default is \"relu\").\n",
        "    '''\n",
        "\n",
        "    def __init__(self, c_in, c_out, T_IN, BATCHSIZE, N_NODE, d_state, d_conv, act=\"relu\"):\n",
        "        super(mamba_layer, self).__init__()\n",
        "        self.act = act  # Activation function\n",
        "        self.c_in = c_in  # Number of input channels\n",
        "        self.c_out = c_out  # Number of output channels\n",
        "        self.T_IN = T_IN  # Number of input time steps\n",
        "        self.BATCHSIZE = BATCHSIZE  # Batch size\n",
        "        self.N_NODE = N_NODE  # Number of nodes (spatial dimension)\n",
        "\n",
        "        # Align layer to match input and output channels\n",
        "        self.align = align(c_in, c_out)\n",
        "\n",
        "        # Mamba model with state-space model (SSM) and local convolution\n",
        "        self.mamba = Mamba(d_model=c_out, d_state=d_state, d_conv=d_conv, expand=2)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Align the input to have the same number of channels as the output\n",
        "        x_in = self.align(x)  # Shape: [batch_size, c_out, T_IN, N_NODE]\n",
        "        # print(f\"Align X-in Shape: {x_in.shape}\")\n",
        "\n",
        "        # Permute dimensions to prepare for the Mamba model (time step dimension first)\n",
        "        x_permut = x_in.permute(2, 0, 3, 1)  # Shape: [T_IN, batch_size, N_NODE, c_out]\n",
        "\n",
        "        # Reshape to [T_IN, batch_size * N_NODE, c_out] for Mamba processing\n",
        "        x_reshape = torch.reshape(x_permut, (self.T_IN, -1, self.c_out))\n",
        "        # print(f\"X-in ReShape: {x_reshape.shape}\")\n",
        "\n",
        "        # Pass the reshaped input through the Mamba model\n",
        "        x_mamba = self.mamba(x_reshape)\n",
        "        # print(f\"X mamba Shape: {x_mamba.shape}\")\n",
        "\n",
        "        # Reshape the Mamba output back to the original dimensions\n",
        "        x_mamba = x_mamba.reshape(self.T_IN, -1, self.N_NODE, self.c_out).permute(1, 3, 0, 2)\n",
        "        # print(f\"Reshape X mamba Shape: {x_mamba.shape}\")\n",
        "\n",
        "        return x_mamba  # Shape: [batch_size, c_out, T_IN, N_NODE]\n"
      ],
      "metadata": {
        "id": "TCADv6_qsKs-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.2 spatio_conv_layer"
      ],
      "metadata": {
        "id": "wTKAjjMz2GKO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class spatio_conv_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Spatio-temporal convolution layer that applies graph convolution over spatial dimensions using a learned filter.\n",
        "\n",
        "    Args:\n",
        "        ks (int): Kernel size (number of spatial filters).\n",
        "        c (int): Number of channels (typically batch size).\n",
        "        Lk (torch.Tensor): Pre-processed Laplacian matrix with shape (3, 207, 207).\n",
        "    \"\"\"\n",
        "    def __init__(self, ks, c, Lk):\n",
        "        super(spatio_conv_layer, self).__init__()\n",
        "        self.Lk = Lk  # Pre-processed Laplacian matrix for graph convolution\n",
        "        self.theta = nn.Parameter(torch.FloatTensor(c, c, ks))  # Learnable filter parameters\n",
        "        self.b = nn.Parameter(torch.FloatTensor(1, c, 1, 1))  # Bias term for convolution\n",
        "        self.reset_parameters()\n",
        "\n",
        "    def reset_parameters(self):\n",
        "        \"\"\"\n",
        "        Initialize the learnable parameters (theta and b) using Kaiming uniform distribution.\n",
        "        \"\"\"\n",
        "        init.kaiming_uniform_(self.theta, a=math.sqrt(5))  # Initialize theta with Kaiming uniform\n",
        "        fan_in, _ = init._calculate_fan_in_and_fan_out(self.theta)  # Calculate fan-in\n",
        "        bound = 1 / math.sqrt(fan_in)  # Define bounds for bias initialization\n",
        "        init.uniform_(self.b, -bound, bound)  # Initialize bias term b uniformly within the defined bounds\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Perform the forward pass of the spatial convolution.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, input_channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after applying the graph convolution and ReLU activation.\n",
        "        \"\"\"\n",
        "        # Perform the graph convolution operation\n",
        "        x_c = torch.einsum(\"knm,bitm->bitkn\", self.Lk, x)  # Apply Laplacian matrix to the input tensor\n",
        "        x_gc = torch.einsum(\"iok,bitkn->botn\", self.theta, x_c) + self.b  # Apply the learned filter and add bias\n",
        "\n",
        "        # Apply ReLU activation and residual connection\n",
        "        return torch.relu(x_gc + x)\n"
      ],
      "metadata": {
        "id": "ZSUUVV7Y2KPU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.3 Output Layer\n"
      ],
      "metadata": {
        "id": "oa-QZcDm2TxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Output layer for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n):\n",
        "        super(output_layer, self).__init__()\n",
        "        # First temporal convolutional layer with GLU activation\n",
        "        # Kernel size is equal to the length of the input time steps\n",
        "        self.tconv1 = temporal_conv_layer(T_IN, c, c, \"GLU\")\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second temporal convolutional layer with sigmoid activation\n",
        "        # Kernel size of 1, output interpreted as a probability\n",
        "        self.tconv2 = temporal_conv_layer(1, c, c, \"sigmoid\")\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = c, output channels = 1\n",
        "        self.fc = nn.Conv2d(c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the output layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after temporal convolution and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first temporal convolutional layer with GLU activation\n",
        "        x_t1 = self.tconv1(x)\n",
        "\n",
        "        # Apply layer normalization (transpose to match LayerNorm dimensions)\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second temporal convolutional layer with sigmoid activation\n",
        "        x_t2 = self.tconv2(x_ln)\n",
        "\n",
        "        # Apply the final fully connected layer to produce the output prediction\n",
        "        return self.fc(x_t2)\n"
      ],
      "metadata": {
        "id": "uO04RoOk2gx8"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class lstm_output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM-based output layer for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "        BATCHSIZE (int): Batch size.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n, BATCHSIZE):\n",
        "        super(lstm_output_layer, self).__init__()\n",
        "        # First LSTM-based temporal layer with GLU activation\n",
        "        # Kernel size is equal to the length of the input time steps\n",
        "        self.tlstm1 = temporal_lstm_layer(c, c, T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second LSTM-based temporal layer with sigmoid activation\n",
        "        # Kernel size of 1, output interpreted as a probability\n",
        "        self.tlstm2 = temporal_lstm_layer(c, c, T_IN, BATCHSIZE, n, act=\"sigmoid\")\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = c, output channels = 1\n",
        "        self.fc = nn.Conv2d(c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the LSTM-based output layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after LSTM layers and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first LSTM-based temporal layer with GLU activation\n",
        "        x_t1 = self.tlstm1(x)\n",
        "\n",
        "        # Apply layer normalization (transpose to match LayerNorm dimensions)\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second LSTM-based temporal layer with sigmoid activation\n",
        "        x_t2 = self.tlstm2(x_ln)\n",
        "\n",
        "        # Apply the fully connected layer and return the last time step's output\n",
        "        # Only the last time step is kept, similar to BERT where only the final token is used for downstream tasks\n",
        "        return self.fc(x_t2)[:, :, -1:, :]\n"
      ],
      "metadata": {
        "id": "pcpV3C-ZR7o6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class attention_lstm_output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    LSTM-based output layer with attention mechanisms for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "        BATCHSIZE (int): Batch size.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n, BATCHSIZE):\n",
        "        super(attention_lstm_output_layer, self).__init__()\n",
        "        # First LSTM-based attention layer with GLU activation\n",
        "        # Kernel size is equal to the length of the input time steps\n",
        "        self.tlstm1 = attention_lstm_layer(c, c, T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second LSTM-based attention layer with sigmoid activation\n",
        "        # Kernel size of 1, output interpreted as a probability\n",
        "        self.tlstm2 = attention_lstm_layer(c, c, T_IN, BATCHSIZE, n, act=\"sigmoid\")\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = 2 * c, output channels = 1\n",
        "        # `2 * c` is used because the attention outputs from the two layers are concatenated\n",
        "        self.fc = nn.Conv2d(2 * c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the LSTM-based output layer with attention mechanisms.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after LSTM attention layers and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first LSTM-based attention layer with GLU activation\n",
        "        x_t1, atten1 = self.tlstm1(x)\n",
        "\n",
        "        # Apply layer normalization (transpose to match LayerNorm dimensions)\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second LSTM-based attention layer with sigmoid activation\n",
        "        x_t2, atten2 = self.tlstm2(x_ln)\n",
        "\n",
        "        # Concatenate the attention outputs along the node dimension\n",
        "        z = torch.cat([atten1, atten2], dim=2)  # Shape: [batch_size, nodes, 2 * channels]\n",
        "\n",
        "        # Use the attention-weighted sum as the output, replacing the previous method of using only the last time step\n",
        "        return self.fc(x_t2)\n"
      ],
      "metadata": {
        "id": "qoBZetl9WMFe"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class gru_output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    GRU-based output layer for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "        BATCHSIZE (int): Batch size.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n, BATCHSIZE):\n",
        "        super(gru_output_layer, self).__init__()\n",
        "        # First GRU-based layer with GLU activation\n",
        "        # Kernel size is equal to the length of the input time steps\n",
        "        self.tgru1 = temporal_gru_layer(c, c, T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second GRU-based layer with sigmoid activation\n",
        "        # Kernel size of 1, output interpreted as a probability\n",
        "        self.tgru2 = temporal_gru_layer(c, c, T_IN, BATCHSIZE, n, act=\"sigmoid\")\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = c, output channels = 1\n",
        "        # The final prediction represents the forecasted traffic flow value\n",
        "        self.fc = nn.Conv2d(c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the GRU-based output layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after GRU layers and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first GRU-based layer with GLU activation\n",
        "        x_t1 = self.tgru1(x)\n",
        "\n",
        "        # Apply layer normalization\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second GRU-based layer with sigmoid activation\n",
        "        x_t2 = self.tgru2(x_ln)\n",
        "\n",
        "        # Return the output of the fully connected layer\n",
        "        # Only the last time step's output is used for the final prediction\n",
        "        # Similar to how BERT uses only the last token's output for downstream tasks\n",
        "        return self.fc(x_t2)[:, :, -1:, :]\n"
      ],
      "metadata": {
        "id": "B8SI3ZnzgxbN"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class transformer_output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Transformer-based output layer for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "        BATCHSIZE (int): Batch size.\n",
        "        HEAD (int): Number of attention heads in the Transformer.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n, BATCHSIZE, HEAD):\n",
        "        super(transformer_output_layer, self).__init__()\n",
        "        # First Transformer-based layer\n",
        "        # Kernel size is equal to the length of the input time steps, channels are adjusted to c\n",
        "        self.trans1 = transformer_layer(c, c, T_IN, BATCHSIZE, n, HEAD)\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second Transformer-based layer with similar settings\n",
        "        self.trans2 = transformer_layer(c, c, T_IN, BATCHSIZE, n, HEAD)\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = c, output channels = 1\n",
        "        # The final prediction represents the forecasted traffic flow value\n",
        "        self.fc = nn.Conv2d(c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Transformer-based output layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after Transformer layers and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first Transformer-based layer\n",
        "        x_t1 = self.trans1(x)\n",
        "\n",
        "        # Apply layer normalization\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second Transformer-based layer\n",
        "        x_t2 = self.trans2(x_ln)\n",
        "\n",
        "        # Return the output of the fully connected layer\n",
        "        # Only the last time step's output is used for the final prediction\n",
        "        # Similar to how BERT uses only the last token's output for downstream tasks\n",
        "        return self.fc(x_t2)[:, :, -1:, :]\n"
      ],
      "metadata": {
        "id": "u7mX6_r_x7lz"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class mamba_output_layer(nn.Module):\n",
        "    \"\"\"\n",
        "    Mamba-based output layer for spatio-temporal prediction.\n",
        "\n",
        "    Args:\n",
        "        c (int): Number of input channels.\n",
        "        T_IN (int): Number of input time steps.\n",
        "        n (int): Number of nodes.\n",
        "        BATCHSIZE (int): Batch size.\n",
        "        d_state (int): State dimension for the Mamba layer.\n",
        "        d_conv (int): Convolutional dimension for the Mamba layer.\n",
        "    \"\"\"\n",
        "    def __init__(self, c, T_IN, n, BATCHSIZE, d_state, d_conv):\n",
        "        super(mamba_output_layer, self).__init__()\n",
        "        # First Mamba-based layer\n",
        "        # Kernel size is equal to the length of the input time steps, channels are adjusted to c\n",
        "        self.mamba1 = mamba_layer(c, c, T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "\n",
        "        # Layer normalization, applied across nodes and channels\n",
        "        self.ln = nn.LayerNorm([n, c])\n",
        "\n",
        "        # Second Mamba-based layer with similar settings\n",
        "        self.mamba2 = mamba_layer(c, c, T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "\n",
        "        # Fully connected layer to produce the final prediction\n",
        "        # Input channels = c, output channels = 1\n",
        "        # The final prediction represents the forecasted traffic flow value\n",
        "        self.fc = nn.Conv2d(c, 1, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "        Forward pass of the Mamba-based output layer.\n",
        "\n",
        "        Args:\n",
        "            x (torch.Tensor): Input tensor with shape (batch_size, channels, time_steps, nodes).\n",
        "\n",
        "        Returns:\n",
        "            torch.Tensor: Output tensor after Mamba layers and fully connected layer.\n",
        "        \"\"\"\n",
        "        # Apply the first Mamba-based layer\n",
        "        x_t1 = self.mamba1(x)\n",
        "\n",
        "        # Apply layer normalization\n",
        "        # Transpose: [batch_size, channels, time_steps, nodes] -> [batch_size, time_steps, nodes, channels]\n",
        "        # After normalization, transpose back to original shape\n",
        "        x_ln = self.ln(x_t1.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "\n",
        "        # Apply the second Mamba-based layer\n",
        "        x_t2 = self.mamba2(x_ln)\n",
        "\n",
        "        # Return the output of the fully connected layer\n",
        "        # Only the last time step's output is used for the final prediction\n",
        "        # Similar to how BERT uses only the last token's output for downstream tasks\n",
        "        return self.fc(x_t2)[:, :, -1:, :]\n"
      ],
      "metadata": {
        "id": "EXU4hRaItf22"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.4 Main Model"
      ],
      "metadata": {
        "id": "14V2pkr02h6C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import X\n",
        "\n",
        "class My_Model(nn.Module):\n",
        "    def __init__(self, bs, T_IN, n, p, ks=None, kt=None, A=None, BATCHSIZE=None, HEAD=None, d_state=None, d_conv=None):\n",
        "        super(My_Model, self).__init__()\n",
        "\n",
        "        if is_TCN:\n",
        "            print(\"Creating TCN MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.tconv1 = temporal_conv_layer(kt, bs[0][0], bs[0][1], \"GLU\")\n",
        "            # cin=16, cout=64\n",
        "            self.tconv2 = temporal_conv_layer(kt, bs[0][1], bs[0][2])\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tconv3 = temporal_conv_layer(kt, bs[1][0], bs[1][1], \"GLU\")\n",
        "            # cin=16, cout=64\n",
        "            self.tconv4 = temporal_conv_layer(kt, bs[1][1], bs[1][2])\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = output_layer(bs[1][2], T_IN-4*(kt-1), n)\n",
        "\n",
        "        elif is_STGCN:\n",
        "            print(\"Creating STGCN MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.tconv1 = temporal_conv_layer(kt, bs[0][0], bs[0][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv2 = temporal_conv_layer(kt, bs[0][1], bs[0][2])\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tconv3 = temporal_conv_layer(kt, bs[1][0], bs[1][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv4 = temporal_conv_layer(kt, bs[1][1], bs[1][2])\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = output_layer(bs[1][2], T_IN-4*(kt-1), n)\n",
        "\n",
        "        elif is_dilated_STGCN:\n",
        "            print(\"Creating Dilated STGCN MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.tconv1 = dilated_temporal_conv_layer(kt, bs[0][0], bs[0][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv2 = dilated_temporal_conv_layer(kt, bs[0][1], bs[0][2])\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tconv3 = dilated_temporal_conv_layer(kt, bs[1][0], bs[1][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv4 = dilated_temporal_conv_layer(kt, bs[1][1], bs[1][2])\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = output_layer(bs[1][2], T_IN, n)\n",
        "\n",
        "        elif is_dilated_no0_STGCN:\n",
        "            print(\"Creating Dilated STGCN MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.tconv1 = dilated_no0_temporal_conv_layer(kt, bs[0][0], bs[0][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv2 = dilated_no0_temporal_conv_layer(kt, bs[0][1], bs[0][2])\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tconv3 = dilated_no0_temporal_conv_layer(kt, bs[1][0], bs[1][1], \"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tconv4 = dilated_no0_temporal_conv_layer(kt, bs[1][1], bs[1][2])\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = output_layer(bs[1][2], T_IN, n)\n",
        "\n",
        "        elif is_STG_LSTM or is_STG_BiLSTM:\n",
        "            if is_STG_LSTM: print(\"Creating STGraph LSTM MODEL!\")\n",
        "            elif is_STG_BiLSTM :\n",
        "                print(\"Creating STGraph BiLSTM MODEL!\")\n",
        "                bs = [[2*ele for ele in c] for c in bs]\n",
        "                bs[0][0] = 1\n",
        "\n",
        "            # cin=1, cout=16\n",
        "            self.tlstm1 = temporal_lstm_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tlstm2 = temporal_lstm_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tlstm3 = temporal_lstm_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tlstm4 = temporal_lstm_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = lstm_output_layer(bs[1][2], T_IN, n, BATCHSIZE)\n",
        "\n",
        "        elif is_STG_AttentionLSTM or is_STG_BiAttentionLSTM:\n",
        "            if is_STG_AttentionLSTM: print(\"Creating STGraph Attention LSTM MODEL!\")\n",
        "            elif is_STG_BiAttentionLSTM :\n",
        "                print(\"Creating STGraph Attention BiLSTM MODEL!\")\n",
        "                bs = [[2*ele for ele in c] for c in bs]\n",
        "                bs[0][0] = 1\n",
        "\n",
        "            # cin=1, cout=16\n",
        "            self.tlstm1 = attention_lstm_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tlstm2 = attention_lstm_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tlstm3 = attention_lstm_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tlstm4 = attention_lstm_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            # self.output = attention_lstm_output_layer(bs[1][2], T_IN, n, BATCHSIZE)\n",
        "            self.tlstm5 = attention_lstm_layer(bs[1][2], bs[1][2], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            self.ln3 = nn.LayerNorm([n, bs[1][2]])\n",
        "\n",
        "            self.tlstm6 = attention_lstm_layer(bs[1][2], bs[1][2], T_IN, BATCHSIZE, n, act=\"sigmoid\")\n",
        "\n",
        "            # 全连接层，cin=16， cout=1， 因为我们的最终输出只是一个车流值的预测\n",
        "            # 这里c*2 是因为我们会concat两个attention后的加群求和，来替换只取最后一列\n",
        "            bs_total = bs[0][1]+bs[0][2]+bs[1][1]+3*bs[1][2]\n",
        "            self.fc = nn.Conv2d(bs_total, 1, 1)\n",
        "\n",
        "        elif is_STG_GRU or is_STG_BiGRU:\n",
        "            if is_STG_GRU: print(\"Creating STGraph GRU MODEL!\")\n",
        "            elif is_STG_BiGRU :\n",
        "                print(\"Creating STGraph BiGRU MODEL!\")\n",
        "                bs = [[2*ele for ele in c] for c in bs]\n",
        "                bs[0][0] = 1\n",
        "\n",
        "            # cin=1, cout=16\n",
        "            self.tgru1 = temporal_gru_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tgru2 = temporal_gru_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tgru3 = temporal_gru_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tgru4 = temporal_gru_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = gru_output_layer(bs[1][2], T_IN, n, BATCHSIZE)\n",
        "\n",
        "        elif is_STG_AttentionGRU or is_STG_BiAttentionGRU:\n",
        "            if is_STG_AttentionGRU: print(\"Creating STGraph Attention GRU MODEL!\")\n",
        "            elif is_STG_BiAttentionGRU :\n",
        "                print(\"Creating STGraph Attention BiGRU MODEL!\")\n",
        "                bs = [[2*ele for ele in c] for c in bs]\n",
        "                bs[0][0] = 1\n",
        "\n",
        "            # cin=1, cout=16\n",
        "            self.tgru1 = attention_gru_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tgru2 = attention_gru_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.tgru3 = attention_gru_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.tgru4 = attention_gru_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            # self.output = attention_lstm_output_layer(bs[1][2], T_IN, n, BATCHSIZE)\n",
        "            self.tgru5 = attention_gru_layer(bs[1][2], bs[1][2], T_IN, BATCHSIZE, n, act=\"GLU\")\n",
        "            self.ln3 = nn.LayerNorm([n, bs[1][2]])\n",
        "\n",
        "            self.tgru6 = attention_gru_layer(bs[1][2], bs[1][2], T_IN, BATCHSIZE, n, act=\"sigmoid\")\n",
        "\n",
        "            # Fully-connected layer, cin=16, cout=1, because our final output is just one prediction of the traffic values.\n",
        "            # c*2 here because we'll concatenate the sum of the two attentions and replace it with just the last column.\n",
        "            bs_total = bs[0][1]+bs[0][2]+bs[1][1]+3*bs[1][2]\n",
        "            self.fc = nn.Conv2d(bs_total, 1, 1)\n",
        "\n",
        "        elif is_STG_TRANSFORMER:\n",
        "            print(\"Creating STGraph TRANSFORMER MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.trans1 = transformer_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, HEAD)\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.trans2 = transformer_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n, HEAD)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.trans3 = transformer_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, HEAD)\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.trans4 = transformer_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n, HEAD)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = transformer_output_layer(bs[1][2], T_IN, n, BATCHSIZE, HEAD)\n",
        "\n",
        "        elif is_STG_MAMBA:\n",
        "            print(\"Creating STGraph MAMBA MODEL!\")\n",
        "            # cin=1, cout=16\n",
        "            self.mamba1 = mamba_layer(bs[0][0], bs[0][1], T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "            # cin=16, cout=16\n",
        "            self.sconv1 = spatio_conv_layer(ks, bs[0][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.mamba2 = mamba_layer(bs[0][1], bs[0][2], T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "            self.ln1 = nn.LayerNorm([n, bs[0][2]])\n",
        "            self.dropout1 = nn.Dropout(p)\n",
        "\n",
        "            # cin=64, cout=16\n",
        "            self.mamba3 = mamba_layer(bs[1][0], bs[1][1], T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "            # cin=16, cout=16\n",
        "            self.sconv2 = spatio_conv_layer(ks, bs[1][1], A)\n",
        "            # cin=16, cout=64\n",
        "            self.mamba4 = mamba_layer(bs[1][1], bs[1][2], T_IN, BATCHSIZE, n, d_state, d_conv)\n",
        "            self.ln2 = nn.LayerNorm([n, bs[1][2]])\n",
        "            self.dropout2 = nn.Dropout(p)\n",
        "\n",
        "            self.output = mamba_output_layer(bs[1][2], T_IN, n, BATCHSIZE, d_state, d_conv)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if is_TCN:\n",
        "            # print(\"Forward TCN MODEL!\")\n",
        "            x_t1 = self.tconv1(x)\n",
        "            x_t2 = self.tconv2(x_t1)\n",
        "            x_ln1 = self.ln1(x_t2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x_drop1 = self.dropout1(x_ln1)\n",
        "\n",
        "            x_t3 = self.tconv3(x_drop1)\n",
        "            x_t4 = self.tconv4(x_t3)\n",
        "            x_ln2 = self.ln2(x_t4.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x_drop2 = self.dropout2(x_ln2)\n",
        "\n",
        "            return self.output(x_drop2)\n",
        "\n",
        "        elif is_STGCN:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x_t1 = self.tconv1(x)\n",
        "            x_s1 = self.sconv1(x_t1)\n",
        "            x_t2 = self.tconv2(x_s1)\n",
        "            x_ln1 = self.ln1(x_t2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x_drop1 = self.dropout1(x_ln1)\n",
        "\n",
        "            x_t3 = self.tconv3(x_drop1)\n",
        "            x_s2 = self.sconv2(x_t3)\n",
        "            x_t4 = self.tconv4(x_s2)\n",
        "            x_ln2 = self.ln2(x_t4.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x_drop2 = self.dropout2(x_ln2)\n",
        "\n",
        "            return self.output(x_drop2)\n",
        "\n",
        "        elif is_dilated_STGCN or is_dilated_no0_STGCN:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x_t1 = self.tconv1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x_t1.shape}\")\n",
        "            x_s1 = self.sconv1(x_t1)\n",
        "            # print(f\"x_s1 Shape: {x_s1.shape}\")\n",
        "            x_t2 = self.tconv2(x_s1)\n",
        "            # print(f\"x_t2 Shape: {x_t2.shape}\")\n",
        "            x_ln1 = self.ln1(x_t2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x_ln1.shape}\")\n",
        "            x_drop1 = self.dropout1(x_ln1)\n",
        "            # print(f\"x_drop1 Shape: {x_drop1.shape}\")\n",
        "\n",
        "            x_t3 = self.tconv3(x_drop1)\n",
        "            # print(f\"x_t3 Shape: {x_t3.shape}\")\n",
        "            x_s2 = self.sconv2(x_t3)\n",
        "            # print(f\"x_s2 Shape: {x_s2.shape}\")\n",
        "            x_t4 = self.tconv4(x_s2)\n",
        "            # print(f\"x_t4 Shape: {x_t4.shape}\")\n",
        "            x_ln2 = self.ln2(x_t4.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x_ln2.shape}\")\n",
        "            x_drop2 = self.dropout2(x_ln2)\n",
        "            # print(f\"x_drop2 Shape: {x_drop2.shape}\")\n",
        "\n",
        "            return self.output(x_drop2)\n",
        "\n",
        "        elif is_STG_LSTM or is_STG_BiLSTM :\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x = self.tlstm1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x = self.sconv1(x)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x = self.tlstm2(x)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x = self.ln1(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x = self.dropout1(x)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x = self.tlstm3(x)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x = self.sconv2(x)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x = self.tlstm4(x)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x = self.ln2(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x = self.dropout2(x)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            return self.output(x)\n",
        "\n",
        "        elif is_STG_AttentionLSTM or is_STG_BiAttentionLSTM:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x1, atten1 = self.tlstm1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x_sconv1 = self.sconv1(x1)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x2, atten2 = self.tlstm2(x_sconv1)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x_ln1 = self.ln1(x2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x_drop1 = self.dropout1(x_ln1)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x3, atten3 = self.tlstm3(x_drop1)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x_sconv2 = self.sconv2(x3)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x4, atten4 = self.tlstm4(x_sconv2)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x_ln2 = self.ln2(x4.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x_drop2 = self.dropout2(x_ln2)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            x5, atten5 = self.tlstm5(x_drop2)\n",
        "            x_ln3 = self.ln3(x5.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x6, atten6 = self.tlstm6(x_ln3)\n",
        "\n",
        "            z = torch.cat([atten1, atten2, atten3, atten4, atten5, atten6], dim=2) #[64, 207, c_out*6]\n",
        "            z = z.permute(0,2,1).unsqueeze(2) #[64, c_out*6, 1, 207]\n",
        "            # Here we use attentional weighted sums instead of just the last column as the output.\n",
        "            return self.fc(z)\n",
        "\n",
        "        elif is_STG_GRU or is_STG_BiGRU:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x = self.tgru1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x = self.sconv1(x)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x = self.tgru2(x)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x = self.ln1(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x = self.dropout1(x)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x = self.tgru3(x)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x = self.sconv2(x)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x = self.tgru4(x)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x = self.ln2(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x = self.dropout2(x)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            return self.output(x)\n",
        "\n",
        "        elif is_STG_AttentionGRU or is_STG_BiAttentionGRU:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x1, atten1 = self.tgru1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x_sconv1 = self.sconv1(x1)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x2, atten2 = self.tgru2(x_sconv1)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x_ln1 = self.ln1(x2.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x_drop1 = self.dropout1(x_ln1)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x3, atten3 = self.tgru3(x_drop1)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x_sconv2 = self.sconv2(x3)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x4, atten4 = self.tgru4(x_sconv2)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x_ln2 = self.ln2(x4.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x_drop2 = self.dropout2(x_ln2)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            x5, atten5 = self.tgru5(x_drop2)\n",
        "            x_ln3 = self.ln3(x5.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            x6, atten6 = self.tgru6(x_ln3)\n",
        "\n",
        "            z = torch.cat([atten1, atten2, atten3, atten4, atten5, atten6], dim=2) #[64, 207, c_out*6]\n",
        "            z = z.permute(0,2,1).unsqueeze(2) #[64, c_out*6, 1, 207]\n",
        "            # Here we use attentional weighted sums instead of just the last column as the output.\n",
        "            return self.fc(z)\n",
        "\n",
        "        elif is_STG_TRANSFORMER:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x = self.trans1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x = self.sconv1(x)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x = self.trans2(x)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x = self.ln1(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x = self.dropout1(x)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x = self.trans3(x)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x = self.sconv2(x)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x = self.trans4(x)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x = self.ln2(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x = self.dropout2(x)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            return self.output(x)\n",
        "\n",
        "        elif is_STG_MAMBA:\n",
        "            # print(\"Forward STGCN MODEL!\")\n",
        "            x = self.mamba1(x)\n",
        "            # print(f\"x_tconv1 Shape: {x.shape}\")\n",
        "            x = self.sconv1(x)\n",
        "            # print(f\"x_s1 Shape: {x.shape}\")\n",
        "            x = self.mamba2(x)\n",
        "            # print(f\"x_t2 Shape: {x.shape}\")\n",
        "            x = self.ln1(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln1 Shape: {x.shape}\")\n",
        "            x = self.dropout1(x)\n",
        "            # print(f\"x_drop1 Shape: {x.shape}\")\n",
        "\n",
        "            x = self.mamba3(x)\n",
        "            # print(f\"x_t3 Shape: {x.shape}\")\n",
        "            x = self.sconv2(x)\n",
        "            # print(f\"x_s2 Shape: {x.shape}\")\n",
        "            x = self.mamba4(x)\n",
        "            # print(f\"x_t4 Shape: {x.shape}\")\n",
        "            x = self.ln2(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "            # print(f\"x_ln2 Shape: {x.shape}\")\n",
        "            x = self.dropout2(x)\n",
        "            # print(f\"x_drop2 Shape: {x.shape}\")\n",
        "\n",
        "            return self.output(x)"
      ],
      "metadata": {
        "id": "4LBzu12H1fis"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Function"
      ],
      "metadata": {
        "id": "q7OtY7cb0x8e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "FLOWPATH = './metrla_complet/metr-la.h5'\n",
        "ADJPATH = './metrla_complet/W_metrla.csv'\n",
        "\n",
        "TRAINRATIO = 0.8\n",
        "TRAINVALSPLIT = 0.125\n",
        "TIMESTEP_PER_HOUR = 12\n",
        "TIMESTEP_IN = 12\n",
        "TIMESTEP_OUT = 3\n",
        "BATCHSIZE = 64\n",
        "\n",
        "########### Process and Split RAW Data ###########\n",
        "set_seed(100)\n",
        "\n",
        "data = pd.read_hdf(FLOWPATH)\n",
        "scaler = StandardScaler()\n",
        "data = scaler.fit_transform(data)\n",
        "\n",
        "train_valXS, train_valYS = getXSYS_single(data, 'TRAIN')\n",
        "testXS, testYS = getXSYS_single(data, 'TEST')\n",
        "\n",
        "train_iter, val_iter = create_dataset(train_valXS, train_valYS, device, 'TRAIN_VALID')\n",
        "test_iter = create_dataset(testXS, testYS, device, 'TEST')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:35.222299Z",
          "iopub.execute_input": "2024-04-03T14:07:35.222703Z",
          "iopub.status.idle": "2024-04-03T14:07:35.228643Z",
          "shell.execute_reply.started": "2024-04-03T14:07:35.222656Z",
          "shell.execute_reply": "2024-04-03T14:07:35.227448Z"
        },
        "trusted": true,
        "id": "p3Q6XwOcStZH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8782d51-f64a-474c-aa32-6ec7eed4be82"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Train_Valid Dataset size: 27403.\n",
            "Train Dataset size: 23977.\n",
            "Valide Dataset size: 3426.\n",
            "Test Dataset size: 6853.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from operator import truediv\n",
        "from itertools import filterfalse\n",
        "set_seed(100)\n",
        "\n",
        "wb_log = True\n",
        "EPOCH = 500\n",
        "models_iter = [\"TCN\", \"STGCN\", \"dilated_STGCN\", \"dilated_no0_STGCN\"]\n",
        "# , \"TCN\", \"STGCN\" \"dilated_STGCN\" \"dilated_no0_STGCN\" \"STG_LSTM\" \"STG_GRU\" STG_TRANSFORMER STG_MAMBA  STG_BiLSTM STG_BiGRU STG_AttentionLSTM STG_BiAttentionLSTM\n",
        "# STG_AttentionGRU STG_BiAttentionGRU\n",
        "\n",
        "for mi in models_iter:\n",
        "    if mi == \"TCN\":\n",
        "        is_TCN = True\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "        print(\"=\"*12, f\" MODEL {mi} \", \"=\"*12,'\\n')\n",
        "    elif mi == \"STGCN\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = True\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "        print(\"\\n\", \"=\"*12, f\" MODEL {mi} \", \"=\"*12,'\\n')\n",
        "    elif mi == \"dilated_STGCN\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = True\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"dilated_no0_STGCN\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = True\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_LSTM\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = True\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_BiLSTM\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = True\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_AttentionLSTM\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = True\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_BiAttentionLSTM\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = True\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_GRU\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = True\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_BiGRU\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = True\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_AttentionGRU\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = True\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_BiAttentionGRU\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = True\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_TRANSFORMER\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = True\n",
        "        is_STG_MAMBA = False\n",
        "    elif mi == \"STG_MAMBA\":\n",
        "        is_TCN = False\n",
        "        is_STGCN = False\n",
        "        is_dilated_STGCN = False\n",
        "        is_dilated_no0_STGCN = False\n",
        "        is_STG_LSTM = False\n",
        "        is_STG_BiLSTM = False\n",
        "        is_STG_GRU = False\n",
        "        is_STG_BiGRU = False\n",
        "        is_STG_AttentionLSTM = False\n",
        "        is_STG_BiAttentionLSTM = False\n",
        "        is_STG_AttentionGRU = False\n",
        "        is_STG_BiAttentionGRU = False\n",
        "        is_STG_TRANSFORMER = False\n",
        "        is_STG_MAMBA = True\n",
        "\n",
        "    # Set up parameters to be stocked in WB\n",
        "    args = Namespace()\n",
        "    args.TIMESTEP_IN = TIMESTEP_IN #12\n",
        "    args.TIMESTEP_OUT = TIMESTEP_OUT #3\n",
        "    args.DATANAME = 'METR-LA'\n",
        "\n",
        "    # Number of nodes of highway\n",
        "    args.N_NODE = 207\n",
        "    args.EPOCH = EPOCH\n",
        "    # Input channel size\n",
        "    args.CHANNEL = 1\n",
        "    args.BATCHSIZE = BATCHSIZE #64\n",
        "    args.LEARN = 0.001\n",
        "    # args.LEARN = 0.001\n",
        "\n",
        "    args.PATIENCE = 10\n",
        "    args.OPTIMIZER = 'Adam' # 'RMSprop'\n",
        "    args.LOSS = 'MAE' #'MSE'\n",
        "\n",
        "    # Spatial Convolution kernel\n",
        "    args.ks = 3\n",
        "    # Temporal convolution kernel\n",
        "    args.kt = 3\n",
        "    # Number of hidden channels\n",
        "    args.bs = [[args.CHANNEL, 16, 64], [64, 16, 64]]\n",
        "    # args.bs = [[args.CHANNEL, 2, 4], [4, 2, 4]]\n",
        "    args.HEAD = 1\n",
        "\n",
        "    # dropout param\n",
        "    args.p = 0.\n",
        "\n",
        "    args.d_state = 2\n",
        "    args.d_conv = 1\n",
        "\n",
        "\n",
        "    if is_TCN: args.MODEL_NAME = 'TCN'\n",
        "    elif is_STGCN: args.MODEL_NAME = 'STGCN'\n",
        "    elif is_dilated_STGCN: args.MODEL_NAME = 'dilated_STGCN'\n",
        "    elif is_dilated_no0_STGCN: args.MODEL_NAME = 'dilated_no0_STGCN'\n",
        "    elif is_STG_LSTM: args.MODEL_NAME = 'STG_LSTM'\n",
        "    elif is_STG_BiLSTM: args.MODEL_NAME = 'STG_BiLSTM'\n",
        "    elif is_STG_AttentionLSTM: args.MODEL_NAME = 'STG_AttentionLSTM'\n",
        "    elif is_STG_BiAttentionLSTM: args.MODEL_NAME = 'STG_BiAttentionLSTM'\n",
        "    elif is_STG_GRU: args.MODEL_NAME = 'STG_GRU'\n",
        "    elif is_STG_BiGRU: args.MODEL_NAME = 'STG_BiGRU'\n",
        "    elif is_STG_AttentionGRU: args.MODEL_NAME = 'STG_AttentionGRU'\n",
        "    elif is_STG_BiAttentionGRU: args.MODEL_NAME = 'STG_BiAttentionGRU'\n",
        "    elif is_STG_TRANSFORMER: args.MODEL_NAME = f'STG_TRANSFORMER_HEAD{args.HEAD}'\n",
        "    elif is_STG_MAMBA: args.MODEL_NAME = f'STG_MAMBA_STATE{args.d_state}_CONV{args.d_conv}'\n",
        "\n",
        "    KEYWORD = args.DATANAME + '_' + args.MODEL_NAME + '_' + datetime.now().strftime(\"%y%m%d%H%M\")\n",
        "    args.SAVE_PATH = '/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/' + KEYWORD\n",
        "    print(args.SAVE_PATH)\n",
        "\n",
        "    if not os.path.exists(args.SAVE_PATH):\n",
        "        os.makedirs(args.SAVE_PATH)\n",
        "\n",
        "    if wb_log:\n",
        "        wandb.login(key=WANDB_TOKEN)\n",
        "        run = wandb.init(project=\"Traffic-Prediction-Survey\",\n",
        "                        name=f\"{args.MODEL_NAME}-{args.DATANAME}-IN{args.TIMESTEP_IN}-OUT{args.TIMESTEP_OUT}\",\n",
        "                        config=vars(args),\n",
        "        )\n",
        "\n",
        "    ############ Initialize model ###########\n",
        "    if is_TCN:\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=None).to(device)\n",
        "    elif is_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_dilated_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_dilated_no0_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_STG_LSTM or is_STG_BiLSTM or is_STG_AttentionLSTM or is_STG_BiAttentionLSTM:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE).to(device)\n",
        "    elif is_STG_GRU or is_STG_BiGRU or is_STG_AttentionGRU or is_STG_BiAttentionGRU:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE).to(device)\n",
        "    elif is_STG_TRANSFORMER:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE, HEAD=args.HEAD).to(device)\n",
        "    elif is_STG_MAMBA:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE, d_state=args.d_state , d_conv=args.d_conv).to(device)\n",
        "\n",
        "    if args.LOSS == 'MSE':\n",
        "        criterion = nn.MSELoss()\n",
        "    if args.LOSS == 'MAE':\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "    if args.OPTIMIZER == 'RMSprop':\n",
        "        optimizer = torch.optim.RMSprop(model.parameters(), lr=args.LEARN)\n",
        "    else:\n",
        "        optimizer = torch.optim.Adam(model.parameters(), lr=args.LEARN)\n",
        "\n",
        "    # if is_STG_TRANSFORMER:\n",
        "    #     scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=30, gamma=0.1)\n",
        "\n",
        "    ########### Train Phase ###########\n",
        "    min_val_loss = np.inf  # Early Stopping\n",
        "    wait = 0  # Waiting steps for Early Stopping\n",
        "\n",
        "    for epoch in tqdm(range(args.EPOCH)):\n",
        "        starttime = datetime.now()\n",
        "        loss_sum, n = 0.0, 0\n",
        "        model.train()\n",
        "        for x, y in train_iter:\n",
        "            # Optimiser gradient to zero\n",
        "            optimizer.zero_grad()\n",
        "            y_pred = model(x)\n",
        "            loss = criterion(y_pred, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            # if is_STG_TRANSFORMER:\n",
        "            #     scheduler.step()\n",
        "\n",
        "            # Recording loss\n",
        "            loss_sum += loss.item() * y.shape[0] # 64\n",
        "            n += y.shape[0]\n",
        "\n",
        "        train_loss = loss_sum / n\n",
        "        # Calculate the loss of the validation set\n",
        "        val_loss = evaluateModel(model, criterion, val_iter)\n",
        "\n",
        "        if val_loss < min_val_loss:\n",
        "            wait = 0\n",
        "            min_val_loss = val_loss\n",
        "            torch.save(model.state_dict(), args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt')\n",
        "        else:\n",
        "            wait += 1\n",
        "            if wait == args.PATIENCE:\n",
        "                print('Early stopping at epoch: %d' % epoch)\n",
        "                break\n",
        "\n",
        "        endtime = datetime.now()\n",
        "        epoch_time = (endtime - starttime).seconds\n",
        "\n",
        "        if wb_log:\n",
        "            wandb.log({\"epoch\": epoch+1,\"epoch_time\":epoch_time,\n",
        "                      \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "        print(f\"epoch{epoch+1}/{args.EPOCH} \", f\"time used:{epoch_time} seconds \", f\"train loss:{train_loss} \", f\"validation loss:{val_loss} \", f\"patience:{wait}\")\n",
        "\n",
        "    ########### Test Phase ###########\n",
        "    print('Model Testing Started ...', time.ctime())\n",
        "    print('TIMESTEP_IN, TIMESTEP_OUT', args.TIMESTEP_IN, args.TIMESTEP_OUT)\n",
        "\n",
        "    if is_TCN:\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=None).to(device)\n",
        "    elif is_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_dilated_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_dilated_no0_STGCN:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk).to(device)\n",
        "    elif is_STG_LSTM or is_STG_BiLSTM or is_STG_AttentionLSTM or is_STG_BiAttentionLSTM:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE).to(device)\n",
        "    elif is_STG_GRU or is_STG_BiGRU or is_STG_AttentionGRU or is_STG_BiAttentionGRU:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE).to(device)\n",
        "    elif is_STG_TRANSFORMER:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE, HEAD=args.HEAD).to(device)\n",
        "    elif is_STG_MAMBA:\n",
        "        A = pd.read_csv(ADJPATH).values\n",
        "        W = weight_matrix(A)\n",
        "        L = scaled_laplacian(W)\n",
        "        Lk = cheb_poly(L, args.ks)\n",
        "        Lk = torch.Tensor(Lk.astype(np.float32)).to(device)\n",
        "        model_pred = My_Model(bs=args.bs, T_IN=args.TIMESTEP_IN, n=args.N_NODE, p=args.p, ks=args.ks, kt=args.kt, A=Lk, BATCHSIZE=args.BATCHSIZE, d_state=args.d_state , d_conv=args.d_conv).to(device)\n",
        "\n",
        "    model_pred.load_state_dict(torch.load(args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt'))\n",
        "\n",
        "    if args.LOSS == 'MSE':\n",
        "        criterion = nn.MSELoss()\n",
        "    if args.LOSS == 'MAE':\n",
        "        criterion = nn.L1Loss()\n",
        "\n",
        "    torch_score = evaluateModel(model_pred, criterion, test_iter)\n",
        "    YS = testYS.copy()\n",
        "    YS_pred = predictModel(model_pred, test_iter)\n",
        "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
        "\n",
        "\n",
        "    YS, YS_pred = np.squeeze(YS), np.squeeze(YS_pred)\n",
        "    YS = scaler.inverse_transform(YS)\n",
        "    YS_pred = scaler.inverse_transform(YS_pred)\n",
        "    print('YS.shape, YS_pred.shape,', YS.shape, YS_pred.shape)\n",
        "\n",
        "    MSE, RMSE, MAE, MAPE = evaluate_func(YS, YS_pred)\n",
        "    np.save(args.SAVE_PATH +'/'+ args.MODEL_NAME + '_prediction.npy', YS_pred)\n",
        "    np.save(args.SAVE_PATH +'/'+args.MODEL_NAME + '_groundtruth.npy', YS)\n",
        "\n",
        "    print('*' * 40)\n",
        "    print(f\"{args.SAVE_PATH}, TEST, Torch {args.LOSS}: {torch_score}\\n\")\n",
        "    print(\"MSE, RMSE, MAE, MAPE, %.10f, %.10f, %.10f, %.10f\\n\" % (MSE, RMSE, MAE, MAPE))\n",
        "    print('Model Testing Ended ...', time.ctime())\n",
        "\n",
        "    if wb_log:\n",
        "        wandb.summary[\"test_torch_MAE\"]= torch_score,\n",
        "        wandb.summary[\"test_MSE\"]= MSE,\n",
        "        wandb.summary[\"test_RMSE\"]= RMSE,\n",
        "        wandb.summary[\"test_MAE\"]= MAE,\n",
        "        wandb.summary[\"test_MAPE\"]= MAPE,\n",
        "        wandb.finish()\n",
        "\n",
        "    del model, model_pred\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-04-03T14:07:35.254184Z",
          "iopub.execute_input": "2024-04-03T14:07:35.2545Z",
          "iopub.status.idle": "2024-04-03T14:07:35.26795Z",
          "shell.execute_reply.started": "2024-04-03T14:07:35.254472Z",
          "shell.execute_reply": "2024-04-03T14:07:35.266896Z"
        },
        "trusted": true,
        "id": "QRcUAISJStZI",
        "outputId": "0361167c-3074-4a1c-b904-7334b794280e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "732215489d884c14b720daef281d04be",
            "d68e45427f0547ed9b18794dcf26f694",
            "8a6f63ccd6854f7c9a1b06112ae8f675",
            "fb23587e81e4475392629494fce22cdd",
            "52558dcc6aa948b8b2f9a12b31618e71",
            "4c7d625e5b394d878c97090f06805437",
            "07f89884c05a4f1ca8dca42cda5ba8c2",
            "140d93622aa24505aa4c608293bd03be",
            "097ca53a64e64a8da87e017ffb3a0c98",
            "3fe4b0c4d7784bc4b6d79d863a45e997",
            "5500d29dca1149deb137d3d6c8d51946",
            "8f3e03dde5274f30ad3f6f203d460d7b",
            "03c3edbc675248ceadd7c01bb7cecdf0",
            "259a55c02de7476ba49f8e979039595e",
            "224a594fab5843b795f8c937127bb69f",
            "e5e2001cfb1c4542be5d64aaaa5dda97",
            "626fb3cab4f545c0948419d859df2e82",
            "2e54d0dffb96496b82ef028b01e5d3fb",
            "27299541c72345898198c70cd7b89c8f",
            "f63d17cdbb3d49788096f4c518c73273",
            "3c941798bdfb45fc9cfc02ffdea26fdd",
            "94643ea2c6a54c7481ebc3b671c942b1",
            "c0e755d78b5c4cde8afa8188d10d2a1f",
            "3721215d16b54fa2a6c723efd0df4d7b",
            "ea50619213d94639b7228e1be175211a",
            "60a2849df78540d9bb00f51b517feae9",
            "ed567d815a4b495ab008f427225cb454",
            "3d666c663d164f0181289bcb81061db6",
            "89b60de633f0460bbf1efe7103a47b2d",
            "2e7dd189ad78418da36de544e9b94522",
            "b138cec91e604eec82dce0d043364910",
            "f0ede87b1e3a45b4885b36d2f8dac736",
            "d64b3801d5164448bb3a066a98383bc7",
            "2143f35d3f5141eeb54860cf20797ae0",
            "240cda871a434c82b0da184732b98a81",
            "f358b7a76fc44a77accebd61f08dca93",
            "db99800246bf4c7297dc590337773f70",
            "5f84cb5831074a00929171dd0e5b7353",
            "7d23888c1ee541c19ce7f59a31f55a19",
            "9481ed10530f4995a37399b4d15e421c",
            "73c82d86ddd243feb6854ab5eba1f333",
            "bfc017f005c04fe0814c60af8a997e7a",
            "20d5d8810a644203bec8d6b0a0079865",
            "563b123138194b68b865d23e9135309f",
            "0926c57994484f3eb7503e3fd56c61ec",
            "5810f3cc38bf43f4a06221c1e799a73e",
            "18571e4e7c1d40aba470170447f5a523",
            "fb0d6932f1c14864a745f9bda8582fed",
            "4f9533baa79e4122bc5a873e4b7c163a",
            "59367b8003794475b9f4c2220414f7b0",
            "d93001e532854ef39cf8d8c4850919d7",
            "a1cb4f02955c4d12bc5e878d222c8957",
            "238f72da0c734f4b93b43692bddb16ee",
            "0b677953ea4041f382ac6a232e046316",
            "f4ebee75a8214fafb112e673d2f3c3c3",
            "0d7ee95ff4a84fb8be026f01dd67d95d",
            "1af6ee831b7a4f1493d1e9efa2aab0f6",
            "d5799b61264a489f80d620c088de6bae",
            "54437f31fd734df0b7cf47e1e22fa956",
            "726b8352e5634dfa8109be6b9e1311ab",
            "9ae356a219534c568359039479a3b6c9",
            "bd65aa02570d40d0be635657e09425de",
            "c972d7580e134b9cae8986ac041f4d74",
            "c261175753974ce39109119d72c65c31",
            "a12d42248e4c4cf98ed9315b5f35c5c0",
            "d47ea30916744539bca05985593efc53",
            "6f39faaed4b54a7d9ed7db8264918155",
            "1121bac1e7f94b29a6e51ad409bb99e9",
            "d3222e6c170c46ac92f9e52f0ac63fc1",
            "7026fd4fe5cd4b45be69d1727c8513d9",
            "634c4ff78fc648ee98cbbeeb63a0edf2",
            "8c1cd294ef904dd18077fe13c5af4d53",
            "3a97c617e66948378c3e54712dfece44",
            "2a94600cd1d4451d9fb6653f0a9d4a04",
            "903417ab9e1e425dbc5e135c87e1225d",
            "e9d8fedbe7de4579847530cc151348ca"
          ]
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "============  MODEL TCN  ============ \n",
            "\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_TCN_2408262010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: W&B API key is configured. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33manoif\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Personal_Project/Traffic_Prediction/wandb/run-20240826_201042-g2w2zh6k</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/g2w2zh6k' target=\"_blank\">TCN-METR-LA-IN12-OUT3</a></strong> to <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/g2w2zh6k' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/g2w2zh6k</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating TCN MODEL!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "732215489d884c14b720daef281d04be"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1/500  time used:6 seconds  train loss:0.21972030653425345  validation loss:0.18640235527453894  patience:0\n",
            "epoch2/500  time used:4 seconds  train loss:0.18668174746884025  validation loss:0.18421701748539535  patience:0\n",
            "epoch3/500  time used:4 seconds  train loss:0.18445797284960413  validation loss:0.18169707757509457  patience:0\n",
            "epoch4/500  time used:4 seconds  train loss:0.18304801860170666  validation loss:0.1813188063353735  patience:0\n",
            "epoch5/500  time used:4 seconds  train loss:0.18210676310830753  validation loss:0.17958946305099316  patience:0\n",
            "epoch6/500  time used:4 seconds  train loss:0.18116086027975917  validation loss:0.1786725593636207  patience:0\n",
            "epoch7/500  time used:4 seconds  train loss:0.1808779484373657  validation loss:0.18008564609188263  patience:1\n",
            "epoch8/500  time used:4 seconds  train loss:0.18016001259847564  validation loss:0.17999515635050045  patience:2\n",
            "epoch9/500  time used:4 seconds  train loss:0.17939149611869398  validation loss:0.17854138170148778  patience:0\n",
            "epoch10/500  time used:4 seconds  train loss:0.17884325817256572  validation loss:0.17825613882864558  patience:0\n",
            "epoch11/500  time used:4 seconds  train loss:0.17873370076479225  validation loss:0.1768341418236094  patience:0\n",
            "epoch12/500  time used:4 seconds  train loss:0.17794114901963617  validation loss:0.1771857759546134  patience:1\n",
            "epoch13/500  time used:4 seconds  train loss:0.1777527615221019  validation loss:0.17821946841057323  patience:2\n",
            "epoch14/500  time used:4 seconds  train loss:0.17720929080714484  validation loss:0.1772890235256606  patience:3\n",
            "epoch15/500  time used:4 seconds  train loss:0.17704968825004394  validation loss:0.1769352543096548  patience:4\n",
            "epoch16/500  time used:4 seconds  train loss:0.17643019259933057  validation loss:0.17571339967197935  patience:0\n",
            "epoch17/500  time used:4 seconds  train loss:0.1761069038211889  validation loss:0.17550805723430535  patience:0\n",
            "epoch18/500  time used:4 seconds  train loss:0.1757194551641939  validation loss:0.17584074079398865  patience:1\n",
            "epoch19/500  time used:4 seconds  train loss:0.17534404667092407  validation loss:0.17452058845003376  patience:0\n",
            "epoch20/500  time used:4 seconds  train loss:0.17468517588784538  validation loss:0.17423555227969728  patience:0\n",
            "epoch21/500  time used:4 seconds  train loss:0.1746142102912632  validation loss:0.17484501012048037  patience:1\n",
            "epoch22/500  time used:4 seconds  train loss:0.17426287553405556  validation loss:0.17523911988533386  patience:2\n",
            "epoch23/500  time used:4 seconds  train loss:0.17369404477915415  validation loss:0.1762810422621898  patience:3\n",
            "epoch24/500  time used:4 seconds  train loss:0.17345673287959404  validation loss:0.17458193888806212  patience:4\n",
            "epoch25/500  time used:4 seconds  train loss:0.17303990213259568  validation loss:0.1746202299487709  patience:5\n",
            "epoch26/500  time used:4 seconds  train loss:0.17302273236236557  validation loss:0.1742999139701283  patience:6\n",
            "epoch27/500  time used:4 seconds  train loss:0.17192314331257677  validation loss:0.17307363903738224  patience:0\n",
            "epoch28/500  time used:4 seconds  train loss:0.1719599823875006  validation loss:0.1742979012869007  patience:1\n",
            "epoch29/500  time used:4 seconds  train loss:0.17155395284945768  validation loss:0.17354333230228502  patience:2\n",
            "epoch30/500  time used:4 seconds  train loss:0.17133109273950098  validation loss:0.1743660174175375  patience:3\n",
            "epoch31/500  time used:4 seconds  train loss:0.17148049531721485  validation loss:0.17253925382081906  patience:0\n",
            "epoch32/500  time used:4 seconds  train loss:0.17076821296160466  validation loss:0.1730858708638861  patience:1\n",
            "epoch33/500  time used:4 seconds  train loss:0.16998258050977524  validation loss:0.17311912933359075  patience:2\n",
            "epoch34/500  time used:4 seconds  train loss:0.17006298459147465  validation loss:0.1733386254039203  patience:3\n",
            "epoch35/500  time used:4 seconds  train loss:0.16994509877077  validation loss:0.172870426143531  patience:4\n",
            "epoch36/500  time used:4 seconds  train loss:0.1699117334686885  validation loss:0.17302584654656475  patience:5\n",
            "epoch37/500  time used:4 seconds  train loss:0.16928367321756835  validation loss:0.17485149369139596  patience:6\n",
            "epoch38/500  time used:4 seconds  train loss:0.16875435759273746  validation loss:0.1737646461446523  patience:7\n",
            "epoch39/500  time used:4 seconds  train loss:0.1685178279273876  validation loss:0.17341891767960574  patience:8\n",
            "epoch40/500  time used:4 seconds  train loss:0.1684320084416608  validation loss:0.17326478676199564  patience:9\n",
            "Early stopping at epoch: 40\n",
            "Model Testing Started ... Mon Aug 26 20:14:08 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 3\n",
            "Creating TCN MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-dfcdfef4ed76>:456: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_pred.load_state_dict(torch.load(args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YS.shape, YS_pred.shape, (6853, 1, 1, 207) (6853, 1, 1, 207)\n",
            "YS.shape, YS_pred.shape, (6853, 207) (6853, 207)\n",
            "****************************************\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_TCN_2408262010, TEST, Torch MAE: 0.19465459452899342\n",
            "\n",
            "MSE, RMSE, MAE, MAPE, 61.7248139531, 7.8565141095, 3.4306959329, 8.4683671510\n",
            "\n",
            "Model Testing Ended ... Mon Aug 26 20:14:09 2024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.019 MB uploaded\\r'), FloatProgress(value=0.11256557581813639, max=1.…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8f3e03dde5274f30ad3f6f203d460d7b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>█▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▅▄▅▅▄▄▃▃▄▃▃▃▂▃▂▂▂▂▃▂▂▂▁▂▂▂▁▁▁▁▁▁▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>40</td></tr><tr><td>epoch_time</td><td>4</td></tr><tr><td>train_loss</td><td>0.16843</td></tr><tr><td>val_loss</td><td>0.17326</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">TCN-METR-LA-IN12-OUT3</strong> at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/g2w2zh6k' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/g2w2zh6k</a><br/> View project at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240826_201042-g2w2zh6k/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ============  MODEL STGCN  ============ \n",
            "\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_STGCN_2408262014\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Personal_Project/Traffic_Prediction/wandb/run-20240826_201415-qmdo14rg</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/qmdo14rg' target=\"_blank\">STGCN-METR-LA-IN12-OUT3</a></strong> to <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/qmdo14rg' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/qmdo14rg</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f63d17cdbb3d49788096f4c518c73273"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1/500  time used:6 seconds  train loss:0.2157506596635886  validation loss:0.1842068879317625  patience:0\n",
            "epoch2/500  time used:6 seconds  train loss:0.18729794436279784  validation loss:0.18380357138921277  patience:0\n",
            "epoch3/500  time used:6 seconds  train loss:0.18503235655202427  validation loss:0.18222837975619482  patience:0\n",
            "epoch4/500  time used:6 seconds  train loss:0.18384331800427345  validation loss:0.181543508965372  patience:0\n",
            "epoch5/500  time used:6 seconds  train loss:0.18248245136082636  validation loss:0.17974302146564222  patience:0\n",
            "epoch6/500  time used:6 seconds  train loss:0.18203439751105724  validation loss:0.18139788381411748  patience:1\n",
            "epoch7/500  time used:6 seconds  train loss:0.18148111549607357  validation loss:0.17827206701301235  patience:0\n",
            "epoch8/500  time used:6 seconds  train loss:0.18037813662383895  validation loss:0.17872131267487482  patience:1\n",
            "epoch9/500  time used:6 seconds  train loss:0.18012007622674164  validation loss:0.18028330093959724  patience:2\n",
            "epoch10/500  time used:6 seconds  train loss:0.17983392222366554  validation loss:0.1774824284108424  patience:0\n",
            "epoch11/500  time used:6 seconds  train loss:0.1793966250763766  validation loss:0.1772393085545291  patience:0\n",
            "epoch12/500  time used:6 seconds  train loss:0.1786819148314488  validation loss:0.17735558098439785  patience:1\n",
            "epoch13/500  time used:6 seconds  train loss:0.17872158199226795  validation loss:0.1769995954272626  patience:0\n",
            "epoch14/500  time used:6 seconds  train loss:0.17825302570460413  validation loss:0.1774424810247399  patience:1\n",
            "epoch15/500  time used:6 seconds  train loss:0.17789533934685875  validation loss:0.17632439518559417  patience:0\n",
            "epoch16/500  time used:6 seconds  train loss:0.17739288017117072  validation loss:0.17555670610694807  patience:0\n",
            "epoch17/500  time used:6 seconds  train loss:0.17696287278604103  validation loss:0.17666162407787933  patience:1\n",
            "epoch18/500  time used:6 seconds  train loss:0.17678901643889677  validation loss:0.17573960660426713  patience:2\n",
            "epoch19/500  time used:6 seconds  train loss:0.17635380296080805  validation loss:0.17467785879351977  patience:0\n",
            "epoch20/500  time used:6 seconds  train loss:0.1764088089215416  validation loss:0.17561985795009366  patience:1\n",
            "epoch21/500  time used:6 seconds  train loss:0.17593353772951922  validation loss:0.17414749989158845  patience:0\n",
            "epoch22/500  time used:6 seconds  train loss:0.17548460546074127  validation loss:0.1744898085836354  patience:1\n",
            "epoch23/500  time used:6 seconds  train loss:0.17522601716466796  validation loss:0.1748731256192425  patience:2\n",
            "epoch24/500  time used:6 seconds  train loss:0.1744701719513507  validation loss:0.17471736488603948  patience:3\n",
            "epoch25/500  time used:6 seconds  train loss:0.1746992434870189  validation loss:0.17552599393514187  patience:4\n",
            "epoch26/500  time used:6 seconds  train loss:0.1748146591797013  validation loss:0.17392146018465848  patience:0\n",
            "epoch27/500  time used:6 seconds  train loss:0.17455479292059262  validation loss:0.17534606658048402  patience:1\n",
            "epoch28/500  time used:6 seconds  train loss:0.17402983100401748  validation loss:0.1758886994723333  patience:2\n",
            "epoch29/500  time used:6 seconds  train loss:0.17403885606192676  validation loss:0.17396857318513517  patience:3\n",
            "epoch30/500  time used:6 seconds  train loss:0.17402643462871498  validation loss:0.17530283750286593  patience:4\n",
            "epoch31/500  time used:6 seconds  train loss:0.1734706051248364  validation loss:0.17434235727028477  patience:5\n",
            "epoch32/500  time used:6 seconds  train loss:0.17289876877769356  validation loss:0.1745090173634603  patience:6\n",
            "epoch33/500  time used:6 seconds  train loss:0.17289555401918802  validation loss:0.17364679898912283  patience:0\n",
            "epoch34/500  time used:6 seconds  train loss:0.1724702177773814  validation loss:0.17330154879219825  patience:0\n",
            "epoch35/500  time used:6 seconds  train loss:0.17221667797570334  validation loss:0.17324608103336817  patience:0\n",
            "epoch36/500  time used:6 seconds  train loss:0.1725024474769894  validation loss:0.17364244868514556  patience:1\n",
            "epoch37/500  time used:6 seconds  train loss:0.17171620383020308  validation loss:0.1761801748145622  patience:2\n",
            "epoch38/500  time used:6 seconds  train loss:0.1715062880799943  validation loss:0.17574307867051284  patience:3\n",
            "epoch39/500  time used:6 seconds  train loss:0.17101849216585457  validation loss:0.1742496012475709  patience:4\n",
            "epoch40/500  time used:6 seconds  train loss:0.17110705580758895  validation loss:0.17255677716883733  patience:0\n",
            "epoch41/500  time used:6 seconds  train loss:0.1702825778625067  validation loss:0.17304243952018505  patience:1\n",
            "epoch42/500  time used:6 seconds  train loss:0.1691214779249178  validation loss:0.17528896692268206  patience:2\n",
            "epoch43/500  time used:6 seconds  train loss:0.16981968259664235  validation loss:0.1745261487926716  patience:3\n",
            "epoch44/500  time used:6 seconds  train loss:0.1686071855784626  validation loss:0.17348507196320057  patience:4\n",
            "epoch45/500  time used:6 seconds  train loss:0.16875518133355205  validation loss:0.17377778340589908  patience:5\n",
            "epoch46/500  time used:6 seconds  train loss:0.16767125194122043  validation loss:0.17533011328248482  patience:6\n",
            "epoch47/500  time used:6 seconds  train loss:0.16731386788805605  validation loss:0.17330775343390564  patience:7\n",
            "epoch48/500  time used:6 seconds  train loss:0.16717229788444674  validation loss:0.1743241597773802  patience:8\n",
            "epoch49/500  time used:6 seconds  train loss:0.16845433322749523  validation loss:0.17425307424459552  patience:9\n",
            "Early stopping at epoch: 49\n",
            "Model Testing Started ... Mon Aug 26 20:19:29 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 3\n",
            "Creating STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-dfcdfef4ed76>:456: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_pred.load_state_dict(torch.load(args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YS.shape, YS_pred.shape, (6853, 1, 1, 207) (6853, 1, 1, 207)\n",
            "YS.shape, YS_pred.shape, (6853, 207) (6853, 207)\n",
            "****************************************\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_STGCN_2408262014, TEST, Torch MAE: 0.19235712553347425\n",
            "\n",
            "MSE, RMSE, MAE, MAPE, 61.4725684145, 7.8404444016, 3.3949415100, 8.3803408650\n",
            "\n",
            "Model Testing Ended ... Mon Aug 26 20:19:30 2024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b138cec91e604eec82dce0d043364910"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▃▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>██▇▆▅▄▅▆▄▄▄▄▃▃▃▂▃▂▂▂▃▂▃▂▃▂▂▁▁▂▃▂▁▁▃▂▂▃▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>49</td></tr><tr><td>epoch_time</td><td>6</td></tr><tr><td>train_loss</td><td>0.16845</td></tr><tr><td>val_loss</td><td>0.17425</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">STGCN-METR-LA-IN12-OUT3</strong> at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/qmdo14rg' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/qmdo14rg</a><br/> View project at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240826_201415-qmdo14rg/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_dilated_STGCN_2408262019\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Personal_Project/Traffic_Prediction/wandb/run-20240826_201937-3kxauww0</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/3kxauww0' target=\"_blank\">dilated_STGCN-METR-LA-IN12-OUT3</a></strong> to <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/3kxauww0' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/3kxauww0</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Dilated STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d23888c1ee541c19ce7f59a31f55a19"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1/500  time used:66 seconds  train loss:0.20918763745413782  validation loss:0.1846540469178246  patience:0\n",
            "epoch2/500  time used:66 seconds  train loss:0.18582560570160372  validation loss:0.1829028107047568  patience:0\n",
            "epoch3/500  time used:66 seconds  train loss:0.18345291354593377  validation loss:0.18180705894000057  patience:0\n",
            "epoch4/500  time used:66 seconds  train loss:0.18194756392664074  validation loss:0.17912689366329504  patience:0\n",
            "epoch5/500  time used:65 seconds  train loss:0.1806836815942998  validation loss:0.17769804598640715  patience:0\n",
            "epoch6/500  time used:66 seconds  train loss:0.1799363089144993  validation loss:0.18145991595634856  patience:1\n",
            "epoch7/500  time used:65 seconds  train loss:0.17879163627815528  validation loss:0.1787898717431805  patience:2\n",
            "epoch8/500  time used:65 seconds  train loss:0.17867484611633516  validation loss:0.1758077271974233  patience:0\n",
            "epoch9/500  time used:65 seconds  train loss:0.17809976619340592  validation loss:0.17660827579828153  patience:1\n",
            "epoch10/500  time used:66 seconds  train loss:0.17738557360240087  validation loss:0.17686982188423822  patience:2\n",
            "epoch11/500  time used:66 seconds  train loss:0.17680264694997863  validation loss:0.17629817252575272  patience:3\n",
            "epoch12/500  time used:66 seconds  train loss:0.17652794536276636  validation loss:0.17519726665550273  patience:0\n",
            "epoch13/500  time used:66 seconds  train loss:0.17608157140280312  validation loss:0.176421923015943  patience:1\n",
            "epoch14/500  time used:65 seconds  train loss:0.17555258750826033  validation loss:0.17465450731690557  patience:0\n",
            "epoch15/500  time used:65 seconds  train loss:0.17540899720065473  validation loss:0.1752798545798988  patience:1\n",
            "epoch16/500  time used:66 seconds  train loss:0.1749749501801444  validation loss:0.17613771931859254  patience:2\n",
            "epoch17/500  time used:66 seconds  train loss:0.17462122569356822  validation loss:0.1760216376809996  patience:3\n",
            "epoch18/500  time used:65 seconds  train loss:0.1743328111289654  validation loss:0.17314115538105795  patience:0\n",
            "epoch19/500  time used:66 seconds  train loss:0.17336052627710047  validation loss:0.17412614413540892  patience:1\n",
            "epoch20/500  time used:65 seconds  train loss:0.17338287731724336  validation loss:0.17667937462293679  patience:2\n",
            "epoch21/500  time used:66 seconds  train loss:0.17295544787277475  validation loss:0.17295749638592786  patience:0\n",
            "epoch22/500  time used:65 seconds  train loss:0.17331286617555308  validation loss:0.17453876690981476  patience:1\n",
            "epoch23/500  time used:65 seconds  train loss:0.17300270547952137  validation loss:0.1730073608297113  patience:2\n",
            "epoch24/500  time used:65 seconds  train loss:0.17196448182658963  validation loss:0.1726117767371842  patience:0\n",
            "epoch25/500  time used:66 seconds  train loss:0.17125321772113755  validation loss:0.17440184139224152  patience:1\n",
            "epoch26/500  time used:65 seconds  train loss:0.17094945418427993  validation loss:0.17369714890804058  patience:2\n",
            "epoch27/500  time used:66 seconds  train loss:0.17036915592528884  validation loss:0.17415228420819584  patience:3\n",
            "epoch28/500  time used:66 seconds  train loss:0.16984344325730047  validation loss:0.17403064375896588  patience:4\n",
            "epoch29/500  time used:66 seconds  train loss:0.16945883720763935  validation loss:0.17329238950162343  patience:5\n",
            "epoch30/500  time used:66 seconds  train loss:0.16924252095284423  validation loss:0.173883056125652  patience:6\n",
            "epoch31/500  time used:66 seconds  train loss:0.16861863759409504  validation loss:0.17503138393668216  patience:7\n",
            "epoch32/500  time used:66 seconds  train loss:0.1682530233729953  validation loss:0.1739025442348331  patience:8\n",
            "epoch33/500  time used:66 seconds  train loss:0.16833104566283424  validation loss:0.17290836640498267  patience:9\n",
            "Early stopping at epoch: 33\n",
            "Model Testing Started ... Mon Aug 26 20:57:06 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 3\n",
            "Creating Dilated STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-dfcdfef4ed76>:456: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_pred.load_state_dict(torch.load(args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YS.shape, YS_pred.shape, (6853, 1, 1, 207) (6853, 1, 1, 207)\n",
            "YS.shape, YS_pred.shape, (6853, 207) (6853, 207)\n",
            "****************************************\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_dilated_STGCN_2408262019, TEST, Torch MAE: 0.19124057263844765\n",
            "\n",
            "MSE, RMSE, MAE, MAPE, 62.4597932965, 7.9031508461, 3.4027264207, 8.2751957595\n",
            "\n",
            "Model Testing Ended ... Mon Aug 26 20:57:30 2024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59367b8003794475b9f4c2220414f7b0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>████▁█▁▁▁████▁▁██▁█▁█▁▁▁█▁███████</td></tr><tr><td>train_loss</td><td>█▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>█▇▆▅▄▆▅▃▃▃▃▃▃▂▃▃▃▁▂▃▁▂▁▁▂▂▂▂▁▂▂▂▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>33</td></tr><tr><td>epoch_time</td><td>66</td></tr><tr><td>train_loss</td><td>0.16833</td></tr><tr><td>val_loss</td><td>0.17291</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dilated_STGCN-METR-LA-IN12-OUT3</strong> at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/3kxauww0' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/3kxauww0</a><br/> View project at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240826_201937-3kxauww0/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_dilated_no0_STGCN_2408262057\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.17.7"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Personal_Project/Traffic_Prediction/wandb/run-20240826_205736-a6d1dwqi</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/a6d1dwqi' target=\"_blank\">dilated_no0_STGCN-METR-LA-IN12-OUT3</a></strong> to <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/a6d1dwqi' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/a6d1dwqi</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating Dilated STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/500 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d5799b61264a489f80d620c088de6bae"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch1/500  time used:85 seconds  train loss:0.21538447319364987  validation loss:0.18229174678324261  patience:0\n",
            "epoch2/500  time used:84 seconds  train loss:0.18593723150142247  validation loss:0.18448152999848702  patience:1\n",
            "epoch3/500  time used:84 seconds  train loss:0.18303089186629357  validation loss:0.17960122281601745  patience:0\n",
            "epoch4/500  time used:84 seconds  train loss:0.18266371699885878  validation loss:0.17812934570923508  patience:0\n",
            "epoch5/500  time used:84 seconds  train loss:0.18075900262622313  validation loss:0.17825500326099553  patience:1\n",
            "epoch6/500  time used:84 seconds  train loss:0.17999460841841558  validation loss:0.17872167890592408  patience:2\n",
            "epoch7/500  time used:83 seconds  train loss:0.17944294686322815  validation loss:0.17814843955091475  patience:3\n",
            "epoch8/500  time used:83 seconds  train loss:0.17910863906760358  validation loss:0.17660549208217383  patience:0\n",
            "epoch9/500  time used:84 seconds  train loss:0.17795380540296224  validation loss:0.17632465637781017  patience:0\n",
            "epoch10/500  time used:84 seconds  train loss:0.1776204247787547  validation loss:0.17637066931071785  patience:1\n",
            "epoch11/500  time used:84 seconds  train loss:0.177147050713928  validation loss:0.17667968913051585  patience:2\n",
            "epoch12/500  time used:84 seconds  train loss:0.17652644907910625  validation loss:0.17595079384626733  patience:0\n",
            "epoch13/500  time used:84 seconds  train loss:0.17614566411052557  validation loss:0.17493782348613326  patience:0\n",
            "epoch14/500  time used:84 seconds  train loss:0.17603910823363939  validation loss:0.17614535180992086  patience:1\n",
            "epoch15/500  time used:84 seconds  train loss:0.1756044112951646  validation loss:0.17530339049861504  patience:2\n",
            "epoch16/500  time used:84 seconds  train loss:0.17522649530195666  validation loss:0.17456135069391426  patience:0\n",
            "epoch17/500  time used:84 seconds  train loss:0.17519297170774273  validation loss:0.1742974270420052  patience:0\n",
            "epoch18/500  time used:84 seconds  train loss:0.17447173651858605  validation loss:0.17395687460794967  patience:0\n",
            "epoch19/500  time used:84 seconds  train loss:0.1742399921606961  validation loss:0.17518203948682606  patience:1\n",
            "epoch20/500  time used:84 seconds  train loss:0.17373615965565972  validation loss:0.17385260408479988  patience:0\n",
            "epoch21/500  time used:84 seconds  train loss:0.17362207655324577  validation loss:0.17436265664896072  patience:1\n",
            "epoch22/500  time used:84 seconds  train loss:0.17315274221702132  validation loss:0.17365781199110925  patience:0\n",
            "epoch23/500  time used:84 seconds  train loss:0.17451377169124954  validation loss:0.17147105518169592  patience:0\n",
            "epoch24/500  time used:84 seconds  train loss:0.1740996832600645  validation loss:0.1743097942489946  patience:1\n",
            "epoch25/500  time used:84 seconds  train loss:0.17298199709150755  validation loss:0.1743056845905067  patience:2\n",
            "epoch26/500  time used:84 seconds  train loss:0.1726946383932193  validation loss:0.17349349840892664  patience:3\n",
            "epoch27/500  time used:84 seconds  train loss:0.1723105088345535  validation loss:0.17453381432230125  patience:4\n",
            "epoch28/500  time used:84 seconds  train loss:0.17192424965589903  validation loss:0.1730165603699492  patience:5\n",
            "epoch29/500  time used:84 seconds  train loss:0.17204190110694917  validation loss:0.1729256931759778  patience:6\n",
            "epoch30/500  time used:84 seconds  train loss:0.1715513716534985  validation loss:0.17271108187678538  patience:7\n",
            "epoch31/500  time used:84 seconds  train loss:0.1715774903401037  validation loss:0.1729344211592705  patience:8\n",
            "epoch32/500  time used:84 seconds  train loss:0.17125004100822927  validation loss:0.1737298469705604  patience:9\n",
            "Early stopping at epoch: 32\n",
            "Model Testing Started ... Mon Aug 26 21:44:02 2024\n",
            "TIMESTEP_IN, TIMESTEP_OUT 12 3\n",
            "Creating Dilated STGCN MODEL!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-33-dfcdfef4ed76>:456: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model_pred.load_state_dict(torch.load(args.SAVE_PATH +'/'+ f'{args.MODEL_NAME}_IN{args.TIMESTEP_IN}.pt'))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "YS.shape, YS_pred.shape, (6853, 1, 1, 207) (6853, 1, 1, 207)\n",
            "YS.shape, YS_pred.shape, (6853, 207) (6853, 207)\n",
            "****************************************\n",
            "/content/drive/MyDrive/Personal_Project/Traffic_Prediction/Saves/METR-LA_dilated_no0_STGCN_2408262057, TEST, Torch MAE: 0.18828952379332273\n",
            "\n",
            "MSE, RMSE, MAE, MAPE, 64.6524029738, 8.0406717987, 3.3989137813, 8.2246107952\n",
            "\n",
            "Model Testing Ended ... Mon Aug 26 21:44:32 2024\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d3222e6c170c46ac92f9e52f0ac63fc1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇███</td></tr><tr><td>epoch_time</td><td>█▅▅▅▅▅▁▁▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅▅</td></tr><tr><td>train_loss</td><td>█▃▃▃▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_loss</td><td>▇█▅▅▅▅▅▄▄▄▄▃▃▄▃▃▃▂▃▂▃▂▁▃▃▂▃▂▂▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>32</td></tr><tr><td>epoch_time</td><td>84</td></tr><tr><td>train_loss</td><td>0.17125</td></tr><tr><td>val_loss</td><td>0.17373</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dilated_no0_STGCN-METR-LA-IN12-OUT3</strong> at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/a6d1dwqi' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey/runs/a6d1dwqi</a><br/> View project at: <a href='https://wandb.ai/anoif/Traffic-Prediction-Survey' target=\"_blank\">https://wandb.ai/anoif/Traffic-Prediction-Survey</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20240826_205736-a6d1dwqi/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "The new W&B backend becomes opt-out in version 0.18.0; try it out with `wandb.require(\"core\")`! See https://wandb.me/wandb-core for more information."
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}